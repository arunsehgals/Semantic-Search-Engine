ed instruction bytes to be transferred from the memory system into the data array. The address associated with the instruction bytes is then stored in the tag array.</p><p>Instruction bytes are read from main memory and then stored in the instruction cache until they are needed. In some embodiments, microprocessors may \u201cpredecode\u201d the instruction bytes before they are stored in the instruction cache. Predecoding typically involves identifying the boundaries between consecutive instructions and possibly identifying the opcode bytes within the instruction. This predecode information is typically stored with the instruction bytes in the instruction cache. When instructions are fetched from the instruction cache, the predecode information is used to speed the alignment and decoding of the instructions.</p><p>After a requested instruction address is output to main memory, a predetermined number of sequential instruction bytes beginning at the requested address are read from main memory, predecoded, and then conveyed to the instruction cache for storage. The instruction bytes are stored into storage locations (\u201ccache lines\u201d) according to their address, typically without regard to what types of instructions are contained within the sequence of instruction bytes.</p><p>One drawback, however, of traditional caches is that they suffer from inefficiencies because branch instructions and branch targets do not naturally occur at cache line boundaries. This may deleteriously affect performance because taken branch instructions residing in the middle of a cache line may cause the end portion of the cache line to be discarded when it is fetched. Furthermore, branch targets that are not located at the start of a cache line may similarly cause the beginning portion of the cache line to be discarded. For example, upon receiving a fetch address, the typical instruction cache reads the entire corresponding cache line, and then selection logic (either internal or external to the instruction cache) selects the desired instructions and discards instruction bytes before the target address and or after a branch instruction.</p><p>In addition to discarding fetched instruction bytes, an additional performance penalty results from the alignment required before the instruction bytes can be properly decoded. While the cache-related problems highlighted above may occur in both RISC and x86 instruction sets, the problems are typically aggravated by the variable-length nature of x86 instructions.</p><p>Thus, a method and apparatus for more easily accessing instruction bytes stored in a cache is desired. In addition, a method that would improve the cache performance of both RISC microprocessors and x86 compatible microprocessors would be particularly desirable.</p><h4>SUMMARY OF THE INVENTION</h4><p>The problems outlined above are in large part solved by a cache memory configured to access stored instructions according to basic blocks. Instruction streams have natural divisions that are determined by branches. These divisions are referred to herein as \u201cbasic blocks\u201d, with the start of a basic block being the target of a branch, and the end being another (taken) branch instruction. Thus, a method for caching instructions in a block oriented manner rather than the conventional power-of-2 memory blocks is contemplated.</p><p>In one embodiment, the method comprises receiving instruction bytes corresponding to a fetch address and decoding the instruction bytes into instructions. Next, basic blocks of instructions are formed by grouping the instructions into basic blocks ending with branch instructions. The basic blocks may be padded with NULL instructions if the basic blocks have less than a predetermined number of instructions. Conversely, the basic blocks may be divided into two or more basic blocks if the basic blocks have more than the predetermined number of instructions. Once formed, the basic blocks are stored into a basic block cache. Pointers corresponding to the basic blocks are stored into a basic block sequence buffer. The pointers are stored with branch prediction information to form predicted sequences of basic blocks which are output by the sequence buffer when it receives a corresponding fetch address. Multiple basic block pointers may be output and fetched from the basic block cache in a particular clock cycle.</p><p>A microprocessor configured to cache basic blocks of instructions is also contemplated. In one embodiment, the microprocessor comprises a basic block cache and a basic block sequence buffer. The basic block cache is configured to store basic blocks, wherein each basic block may comprise a number of instructions and may end with a branch instruction. The basic block sequence buffer comprises a plurality of storage locations, each configured to store a block sequence entry. The block sequence entry has an address tag and one or more basic block pointers. The address tag corresponds to the fetch address of a particular basic block, and the pointers point to basic blocks that follow that particular basic block in a predicted order. Each block sequence entry may contain multiple basic block pointers and branch prediction information to select the basic block that is predicted to follow the block corresponding to the address tag.</p><p>A computer system configured to utilize a basic block oriented cache is also disclosed. In one embodiment, the system comprises a microprocessor having a basic block cache and a basic block sequence buffer. The basic block cache and basic block sequence buffer may be configured as described above. A CPU bus may be coupled to the microprocessor, and a modem may be coupled to the CPU bus via a bus bridge.</p><?BRFSUM description=\"Brief Summary\" end=\"tail\"?><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"lead\"?><h4>BRIEF DESCRIPTION OF THE DRAWINGS</h4><p>Other objects and advantages of the invention will become apparent upon reading the following detailed description and upon reference to the accompanying drawings in which:</p><p>FIG. 1 is a diagram illustrating the generic format of the x86 instruction set.</p><p>FIG. 2 is a block diagram of one embodiment of a microprocessor configured to employ basic block oriented instruction caching.</p><p>FIG. 3 is block diagram illustrating details of one embodiment of the basic block sequence buffer (BBSB) and basic block cache (BBC) from FIG. <b>2</b>.</p><p>FIG. 4 is block diagram illustrating details of another embodiment of the BBSB and BBC from FIG. <b>2</b>.</p><p>FIG. 5 is a diagram illustrating one embodiment of potential pipeline stages within the microprocessor of FIG. <b>2</b>.</p><p>FIG. 6 is a diagram illustrating one embodiment of a basic block tree showing the possible paths from a single basic block.</p><p>FIG. 7 is a table illustrating one embodiment of a sequence of accesses or basic blocks.</p><p>FIG. 8 is a diagram depicting an exemplary address scheme for the BBSB of FIG. <b>2</b>.</p><p>FIG. 9 is an illustration of one embodiment of a sequence of basic blocks.</p><p>FIG. 10A is a table of sample addresses from a basic block sequence.</p><p>FIG. 10B is a diagram illustrating one possible method for storing information about basic blocks.</p><p>FIG. 11 illustrates one embodiment of an exemplary storage line within the BBSB of FIG. <b>2</b>.</p><p>FIG. 12 illustrates another embodiment of the BBSB from FIG. <b>2</b>.</p><p>FIG. 13 illustrates one possible configuration of the functional units from FIG. <b>2</b>.</p><p>FIG. 14 is a diagram detailing one embodiment of a cache line within one embodiment of the BBC from FIG. <b>2</b>.</p><p>FIG. 15 is a diagram of an exemplary sequence of instructions.</p><p>FIG. 16 is a diagram of the operational pipeline of another embodiment of the microprocessor from FIG. <b>2</b>.</p><p>FIG. 17 is a diagram illustrating an exemplary latency of instructions propagating through one embodiment of the microprocessor from FIG. <b>2</b>.</p><p>FIG. 18 is a diagram illustrating relative basic block positions.</p><p>FIG. 19 is a diagram illustrating one exemplary division of INV_ADR.</p><p>FIG. 20 is a diagram showing one possible method for generating INV_ADR_LOW.</p><p>FIG. 21 is a diagram illustrating one example of exceeding maximum basic block length.</p><p>FIG. 22 is a diagram illustrating improper invalidation of a basic block.</p><p>FIG. 23 is a diagram illustrating changes to basic blocks as the result of self-modifying code.</p><p>FIG. 24 is a diagram illustrating a situation which may result in the loading of an improper basic block.</p><p>FIG. 25 is a diagram illustrating pointers to basic blocks.</p><p>FIG. 26 is a diagram illustrating code with multiple jump targets.</p><p>FIG. 27 is a diagram illustrating one possible method for storing instructions within one embodiment of the BBC from FIG. <b>2</b>.</p><p>FIG. 28 is a diagram illustrating another possible method for storing instructions within one embodiment of the BBC from FIG. <b>2</b>.</p><p>FIG. 29 is a diagram illustrating one possible overlapping scenario for basic blocks.</p><p>FIG. 30 is a diagram illustrates a \u201cworst case\u201d scenario for the basic block overlapping from FIG. <b>29</b>.</p><p>FIG. 31 is a diagram illustrating multiple entry lookup within one embodiment of the BBC from FIG. <b>2</b>.</p><p>FIG. 32 is a diagram illustrating instruction sequences with different basic block footprints.</p><p>FIG. 33 is a diagram illustrating an example of sequence entries within one embodiment of the BBSB from FIG. <b>2</b>.</p><p>FIG. 34 is a block diagram of one embodiment of a computer system configured to utilize the microprocessor of FIG. <b>2</b>.</p><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"tail\"?><?DETDESC description=\"Detailed Description\" end=\"lead\"?><p>While the present invention is susceptible to various modifications and alternative forms, specific embodiments thereof are shown by way of example in the drawings and will herein be described in detail. It should be understood, however, that the drawings and detailed description thereto are not intended to limit the invention to the particular form disclosed, but on the contrary, the intention is to cover all modifications, equivalents and alternatives falling within the spirit and scope of the present invention as defined by the appended claims.</p><h4>DETAILED DESCRIPTION OF SEVERAL EMBODIMENTS</h4><p>First, a general description of one embodiment of a superscalar microprocessor configured to store instructions in a \u201cbasic block oriented\u201d instruction cache will be given. After the general description, more details of the operation of the instruction cache and basic block oriented nature of microprocessor <b>10</b> will be discussed.</p><p>Exemplary Embodiment of a Microprocessor</p><p>Turning now to FIG. 2, a block diagram of one embodiment of a microprocessor <b>10</b> is shown. Microprocessor <b>10</b> includes a prefetch/predecode unit <b>12</b>, a branch prediction unit <b>14</b>, an instruction cache <b>16</b>, an instruction alignment unit <b>18</b>, a decode unit <b>20</b>, a plurality of reservation stations <b>22</b>A-<b>22</b>N, a plurality of functional units <b>24</b>A-<b>24</b>N, a load/store unit <b>26</b>, a data cache <b>28</b>, a register file <b>30</b>, a reorder buffer <b>32</b>, an MROM unit <b>34</b>, a floating point unit (FPU) <b>36</b>, a multiplexer <b>40</b>, a basic block sequence buffer (BBSB) <b>42</b>, a basic block cache (BBC) <b>44</b>, and fetch logic <b>46</b>. Elements referred to herein with a particular reference number followed by a letter may be collectively referred to by the reference number alone. For example, functional units <b>24</b>A-<b>24</b>N may be collectively referred to a