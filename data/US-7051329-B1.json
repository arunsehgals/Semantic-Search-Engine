f one embodiment of a processor, in the form of a general-purpose microprocessor <b>200</b>, in which the present invention may be implemented. The microprocessor <b>200</b> described below is a multithreaded (MT) processor and capable of processing multiple instruction threads simultaneously. However, the teachings of the present invention described below are fully applicable to other processors that process multiple instruction threads in an interleaved manner and also to single thread processors which have the capabilities to process multiple instructions either in parallel or in an interleaved manner. In one embodiment, the microprocessor <b>200</b> may be an Intel Architecture (IA) microprocessor that is capable of executing an Intel Architecture instruction set.</p>\n<p num=\"p-0034\">The microprocessor <b>200</b> comprises an in-order front end, an out-of-order execution core and an in-order retirement back end. The microprocessor <b>200</b> includes a bus interface unit <b>202</b> which functions as an interface between the microprocessor <b>200</b> and other components (e.g., main memory unit) of a computer system within which the microprocessor <b>200</b> may be implemented. The bus interface unit <b>202</b> couples the microprocessor <b>200</b> to a processor bus (not shown) via which data and control information are transferred between the microprocessor <b>200</b> and other system components (not shown). The bus interface unit <b>202</b> includes Front Side Bus (FSB) logic <b>204</b> that controls and facilitates communications over the processor bus. The bus interface unit <b>202</b> also includes a bus queue <b>206</b> that is used to provide a buffering function with respect to the communications over the processor bus. The bus interface unit <b>202</b> receives bus requests <b>208</b> from a memory execution unit <b>212</b>. The bus interface unit <b>202</b> also sends snoops or bus returns to the memory execution unit <b>212</b>.</p>\n<p num=\"p-0035\">The memory execution unit <b>212</b> is structured and configured to function as a local memory within the microprocessor <b>200</b>. The memory execution unit <b>212</b> includes a unified data and instruction cache <b>214</b>, a data Translation Lookaside Buffer (TLB) <b>216</b>, and a memory ordering logic <b>218</b>. The memory execution unit <b>212</b> receives instruction fetch requests <b>220</b> from a microinstruction translation engine (MITE) <b>224</b> and provides raw instructions <b>225</b> to the MITE <b>224</b>. The MITE <b>224</b> decodes the raw instructions <b>225</b> received from the memory execution unit <b>212</b> into a corresponding set of microinstructions, also referred to as micro-operations. Decoded microinstructions <b>226</b> are sent by the MITE <b>224</b> to a trace delivery engine (TDE) <b>230</b>.</p>\n<p num=\"p-0036\">The TDE <b>230</b> functions as a microinstruction cache and is the primary source of microinstructions for a downstream execution unit <b>270</b>. The TDE <b>230</b> includes a trace cache <b>232</b>, a trace branch predictor (BTB) <b>234</b>, a micro-code sequencer <b>236</b>, and a micro-operation (uop) queue <b>238</b>. By having a microinstruction caching function within the processor pipeline, the TDE <b>230</b> and specifically the trace cache <b>232</b> can leverage the work done by the MITE <b>224</b> to provide a relatively high microinstruction bandwidth. In one embodiment, the trace cache <b>232</b> may comprise a <b>256</b> entry, 8 way set associate memory. The term \u201ctrace\u201d, in one embodiment, refers to a sequence of microinstructions stored as entries in the trace cache <b>232</b> with each entry having pointers to preceding and proceeding microinstructions in the trace. Therefore, the trace cache <b>232</b> can facilitate high-performance sequencing in that the address of the next entry to be accessed to obtain a subsequent microinstruction is known before a current access is completed. The trace cache branch predictor <b>234</b> provides local branch predictions with respect to traces within the trace cache <b>232</b>. The trace cache <b>232</b> and the microcode sequencer <b>236</b> provide microinstructions to the micro-op queue <b>238</b>.</p>\n<p num=\"p-0037\">The microinstructions are then fed from the micro-op queue <b>238</b> to a cluster (also referred to as the Rename, Reservation Station, Replay, and Retirement or RRRR cluster) <b>240</b>. The RRRR cluster <b>240</b>, in one embodiment, is responsible for controlling the flow of the microinstructions received from the TDE <b>230</b> through the rest of the microprocessor <b>200</b>. The functions performed by the RRRR cluster <b>240</b> include allocating the resources used for the execution of the microinstructions received from TDE <b>230</b>; converting references to external or logical registers into internal or physical register references; scheduling and dispatching the microinstructions for execution to an execution unit <b>270</b>; providing those microinstructions that need to be re-executed to the execution unit <b>270</b>; and retiring those microinstructions that have completed execution and are ready for retirement. The structure and operation of the RRRR cluster <b>240</b> are described in more detail below. In the event that the resources are insufficient or unavailable to process a microinstruction or a set of microinstructions, the RRRR cluster <b>240</b> will assert a stall signal <b>282</b> that is propagated to the TDE <b>230</b>. The stall signal <b>282</b> is then updated and sent by the TDE <b>230</b> to the MITE <b>224</b>.</p>\n<p num=\"p-0038\">The microinstructions that are ready for execution are dispatched from the RRRR cluster <b>240</b> to the execution unit <b>270</b>. In one embodiment, the execution unit <b>270</b> includes a floating point execution engine <b>274</b>, an integer execution engine <b>276</b>, and a level <b>0</b> data cache <b>278</b>. In one embodiment in which the microprocessor <b>200</b> executes the IA<b>32</b> instruction set.</p>\n<p num=\"p-0039\"><figref idrefs=\"DRAWINGS\">FIG. 3</figref> shows a block diagram of one embodiment of the RRRR cluster <b>240</b> described in <figref idrefs=\"DRAWINGS\">FIG. 2</figref> above. The RRRR cluster <b>240</b> as shown in <figref idrefs=\"DRAWINGS\">FIG. 3</figref> includes a register allocation table (RAT) <b>301</b>, an allocator and free-list manager (ALF) <b>311</b>, an instruction queue (IQ) <b>321</b>, a reorder buffer (ROB) <b>331</b>, a scheduler and scoreboard unit (SSU) <b>341</b>, and a checker and replay unit (CRU) <b>351</b>.</p>\n<p num=\"p-0040\">In the present embodiment, the TDE <b>230</b> delivers the microinstructions (UOPs) to both the ALF <b>311</b> and the RAT <b>301</b>. The ALF <b>311</b> is responsible for allocating most of the resources needed for the execution of the UOPs received from the TDE <b>230</b>. The ALF <b>311</b> includes a free-list manager structure (FLM) <b>315</b> that is used to maintain a history of register allocation. The RAT (also referred to as register renamer) <b>301</b> renames the logical registers specified in each UOP to the appropriate physical register pointers to remove the dependencies caused by register reuse. Once the ALF <b>311</b> and the RAT <b>301</b> have completed their corresponding functions, the UOPs are sent to the IQ <b>321</b> for temporary holding prior to being dispatched for execution by the SSU <b>341</b>. In the embodiment shown in <figref idrefs=\"DRAWINGS\">FIG. 3</figref>, the IQ <b>321</b> is responsible for providing the information about each UOP to the SSU <b>341</b> so that the SSU <b>341</b> can dispatch the respective UOP to the proper execution unit based on data dependency. In one embodiment, the IQ <b>321</b> includes a memory instruction address queue (MIAQ) <b>323</b>, a general instruction address queue (GIAQ) <b>325</b>, and an instruction data queue (IDQ) <b>327</b>. In one embodiment, the MIAQ <b>323</b> and the GIAQ <b>325</b> are used to hold and feed certain time-critical information to the SSU <b>341</b> as quickly as needed. The time-critical information include the UOP's sources and destinations, UOP latency, etc. Depending on the type of input UOP, the ALF <b>311</b> determines whether the MIAQ <b>323</b> or the GIAQ <b>325</b> will be used to hold the time-critical information for the respective input UOP. The MIAQ <b>323</b> is used for memory UOPs (i.e., UOPs that require memory access). The GIAQ <b>325</b> is used for non-memory UOPs (i.e., UOPs that do not require memory access). The IDQ <b>327</b> is used to hold the less time-critical information such as the opcode and immediate data.</p>\n<p num=\"p-0041\">When a UOP's sources are ready and an execution unit is available, the SSU <b>341</b> schedules and dispatches the UOP for execution. There are instances when some UOPs may produce incorrect data, for example due to a level <b>0</b> data cache miss. If a particular UOP produces incorrect data or uses incorrect data in its execution, the CRU <b>351</b> will be informed of the need for this particular UOP to be re-executed or replayed until the correct results are obtained. The checker of the CRU <b>351</b> examines each UOP after its execution to determine whether the respective UOP needs to be re-executed. If so, the replay manager of the CRU <b>351</b> is responsible for re-dispatching the respective UOP to the appropriate execution unit for re-execution. If the checker determines that a particular UOP does not need to be re-executed, that particular UOP will be sent to the ROB <b>331</b> for retirement.</p>\n<p num=\"p-0042\">The ROB <b>331</b> is responsible for retiring each UOP in its original logical program order once its execution has been completed and it is ready for retirement (i.e. no replay). In addition, the ROB <b>331</b> is responsible for handling internal and external events. Examples of internal events include exceptions signaled by the write back of various UOPs such as floating point denormal assist or other events signaled by UOPs that need to be handled by the microcode (e.g., assists). External events include interrupts, page fault, SMI requests, etc. In one embodiment, the ROB <b>331</b> is the unit responsible for ensuring that all events are serviced in accordance with the architectural requirements of the microprocessor. There are several conditions like events, interrupts, halt, reset, etc. that will cause the machine to change mode or to switch between MT and ST configuration. Whenever the ROB <b>331</b> detects such a condition, it asserts a signal or a set of signals (referred to as CRNuke herein) which causes all the UOPs being processed but not retired or committed to be flushed. The ROB <b>331</b> then provides the TDE <b>230</b> with the address of the microinstruction from which to start sequencing UOPs to handle the event. For example, if the memory cluster detects a page fault exception on a load UOP, it will transmit a signal to the ROB <b>331</b> to alert the ROB <b>331</b> of this event. When the ROB <b>331</b> reaches this load UOP, it will assert the signal CRNuke and not commit any state for any of the UOPs including the load UOP and those following it. The ROB <b>331</b> will then send the appropriate information to the TDE <b>230</b> to start sequencing UOPs to service the page fault exception.</p>\n<p num=\"p-0043\">In one embodiment, the ROB <b>331</b> is responsible for detecting and controlling transitions of the machine from single thread mode to multi-thread mode and back. It performs its corresponding function by detecting certain events which can be either internal or external and asserting CRNuke to the rest of the machine and also asserting signals to communicate the new state of the machine. The rest of the machine reacts to the CRNuke signal and the new state signals to enter or exit MT mode or ST mode.</p>\n<p num=\"p-0044\">In one embodiment, the resources that are allocated by the ALF <b>311</b> for the execution of the incoming UOPs include the following:</p>\n<p num=\"p-0045\">1. Sequence number given to each UOP to track the original logical program order of the respective UOP. In one embodiment, the sequence number given to each UOP within a particular thread is unique with respect to other UOPs within that particular thread. The sequence number is used for the in-order retirement of the UOPs once their executions are completed. The sequence number of each UOP is also used in the event that the input UOPs are to be executed in-order.</p>\n<p num=\"p-0046\">2. Entry in the Free List Manager (FLM) <b>315</b> given to each UOP to allow the rename history of the respective UOP to be tracked and recovered in case there is problem with the execution of a particular UOP and it needs to be re-executed.</p>\n<p num=\"p-0047\">3. Entry in the Reorder Buffer (ROB) <b>331</b> given to each UOP to allow the respective UOP to be retired in-order once its execution is completed successfully and the UOP is ready to be retired.</p>\n<p num=\"p-0048\">4. Entry in the physical register file given to each UOP to store the operand data needed for the execution of the respective UOP and the result produced therefrom.</p>\n<p num=\"p-0049\">5. Entry in the Load Buffer given to each UOP that needs to receive data from the MEU <b>212</b> (also referred to as the memory execution cluster).</p>\n<p num=\"p-0050\">6. Entry in the Store Buffer given to each UOP that is to produce some data to be stored in the memory execution cluster.</p>\n<p num=\"p-0051\">7. Entry in the IDQ <b>327</b> given to each UOP to hold the instruction information before the respective UOP is dispatched by the SSU <b>341</b> to the execution unit <b>270</b>.</p>\n<p num=\"p-0052\">8. Entry in the MIAQ <b>323</b> given to each memory UOP or entry in the GIAQ <b>325</b> given to each non-memory UOP to hold the time-critical information for the respective UOP before it is dispatched by the SSU <b>341</b> to the execution unit <b>270</b>.</p>\n<p num=\"p-0053\">In one embodiment, the ALF <b>311</b> is responsible for determining which resources are required for the execution of an input UOP received from the TDE <b>230</b> and how much of required resources need to be allocated for the respective UOP. For example, the ALF <b>311</b>, upon receiving a UOP from the TDE <b>230</b>, will determine whether a load buffer entry is needed and will allocate the appropriate load buffer entry for the respective UOP if there is an entry available in the load buffer. If no entry is available, the ALF <b>311</b> will generate a stall signal <b>282</b> as shown in <figref idrefs=\"DRAWINGS\">FIG. 2</figref> to inform the TDE <b>230</b> and other units within the processor that the incoming UOP cannot be allocated and certain units within the processor, for example the TDE <b>230</b>, need to stall until the stall conditions are cleared. In one embodiment, the ALF <b>311</b> provides the appropriate allocation information (e.g. allocation pointers) to other units within the RRRR cluster <b>240</b> including the IQ <b>321</b>, the RAT <b>301</b>, the ROB <b>331</b> and other units outside of the RRRR cluster <b>240</b>, for example the MEU <b>212</b> (FIG. <b>2</b>).</p>\n<p num=\"p-0054\">In one embodiment, the ALF <b>311</b> uses certain information maintained by other units such as a set of pointers referred to as tail pointers to determine, with respect to a particular resource such as a load buffer, the amount of free entries available for allocation. The ALF <b>311</b> also receives other signals such as clear signals due to branch misprediction (e.g., JEClear and CRClear) that are used to determine whether to generate a stall signal.</p>\n<p num=\"p-0055\">In one embodiment, the microprocessor <b>200</b> can operate in either a single thread (ST) mode or a multithread (MT) mode based upon a control input signal. In one embodiment, the control input signal indicating whether the microprocessor <b>200</b> is to operate in ST or MT mode is provided by the operating system. As explained above, the ALF unit <b>311</b>, in the present embodiment, is responsible for allocating most of the processor resources that are used for the execution of a particular UOP in a particular thread. The various resources allocated by the ALF unit <b>311</b> include the ROB <b>331</b>, the FLM <b>315</b>, the MIAQ <b>323</b>, the GIAQ <b>325</b>, the IDQ <b>327</b>,.the load buffer (LB) (not shown), the store buffer (SB) (not shown), and the physical register file entries that are required by the input UOPs. Each of the resources mentioned above contains a predetermined number of resource elements or entries that are to be allocated based upon the need of the respective UOPs and the availability of those resource elements or entries. In one embodiment, for example, the ROB <b>331</b> contains 126 entries, the FLM <b>315</b> contains 126 entries, the IDQ <b>327</b> contains 126 entries, the GIAQ <b>325</b> contains 32 entries, the MIAQ <b>323</b> contains 32 entries, the load buffer contains 48 entries, the store buffer contains 24 entries, and the physical register file contains 127 entries.</p>\n<p num=\"p-0056\">In the discussion that follows, it is assumed that there are two threads, thread <b>0</b> (T<b>0</b>) and thread <b>1</b> (T<b>1</b>) that can be executed concurrently by the microprocessor <b>200</b> in MT mode or executed individually in ST mode. However, the teachings of the present invention should not be limited to two threads and everything discussed herein equally applies to a processing environment in which more than two threads are executed concurrently. In addition, the discussion below is focused on the resource computation and allocation performed by the ALF unit <b>311</b> with respect to one exemplary queue, referred to hereinafter as Q, that is configured to operate as a circular queue or buffer. However, the teachings of the present invention is equally applicable to any other processor resource or any other data structure including, but not limited to, a non-circular queue structure, a linked-list structure, an array structure, a tree structure, etc.</p>\n<p num=\"p-0057\">In ST mode or ST configuration, each processor resource used in the execution of the UOPs is allocated to the \u201cworking\u201d thread, either thread <b>0</b> or thread <b>1</b>. The working thread is the particular thread to which the current set of UOPs received from the TDE <b>230</b> belong with respect to the current processing period. In one embodiment, the TDE <b>230</b> supplies as many as three valid UOPs per a processing clock cycle. AU valid UOPs in each clock cycle are tagged with one thread bit indicating the particular thread to which the respective allocation clock belongs. The thread bit is used to identify which of the two threads is the current working thread. In addition, the TDE <b>230</b> is responsible for supplying the correct valid bits for the set of UOPs that the TDE <b>230</b> delivers to the RRRR cluster <b>240</b>. Each UOP received from the TDE <b>230</b> therefore is tagged with a valid bit indicating whether the respective UOP is a valid UOP. When the TDE <b>230</b> has no valid UOPs to be allocated, the TDE <b>230</b> is responsible for driving the valid bits to invalid status. The UOPs within each thread are delivered by the TDE <b>230</b> to the RRRR cluster <b>240</b> in their original sequential program order.</p>\n<p num=\"p-0058\">In MT mode or MT configuration, each of the queues or buffers used for the execution of the UOPs is partitioned into two portions, one portion is to be used for thread <b>0</b> and the other portion is used for thread <b>1</b>. In one embodiment, the two portions are sized equally so that each thread is given the same number of queue or buffer entries. In one embodiment, the physical registers are a common resource to be shared by thread <b>0</b> and thread <b>1</b> on a first come, first served basis and there is no partition of the physical registers between the two threads.</p>\n<p num=\"p-0059\">In one embodiment, the queues or buffers to be allocated are configured as circular queues or c