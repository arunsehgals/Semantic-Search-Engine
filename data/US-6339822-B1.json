eliminary issue positions are then merged to a set of aligned issue positions corresponding to each decoder within decode unit <b>20</b>, such that the aligned issue positions contain the three instructions which are prior to other instructions within the preliminary issue positions in program order. In this embodiment, the first decoder within decode unit <b>20</b> receives an instruction which is prior to (in program order) instructions concurrently received by the second and third instruction decoders within decode unit <b>20</b>. Similarly, the second decoder within decode unit <b>20</b> receives an instruction which is prior to (in program order) the instruction concurrently received by the third decoder within decode unit <b>20</b>. As previously noted, predecode information generated by predecode unit <b>12</b> and stored in instruction cache <b>16</b> may be used to speed the alignment process.</p><p>MROM unit <b>34</b> monitors the instructions, and when it detects an instruction that is too complex for decode unit <b>20</b>, it replaces the instruction with a series of microcode instructions. The less complex instructions are decoded within decode unit <b>20</b>. Decode unit <b>20</b> identifies the different fields within the instruction and expands the instruction into a predetermined internal format that is more convenient for functional units <b>24</b>A-<b>24</b>N than the standard instruction format. Note that if microprocessor <b>10</b> is configured to execute only RISC instructions, alignment unit <b>18</b>, MROM unit <b>34</b>, and decode unit <b>20</b> may be greatly simplified or eliminated.</p><p>Decode unit <b>20</b> is configured to decode instructions received from instruction alignment unit <b>18</b>. Register operand information is also detected and decoded. This information is routed to register file <b>30</b> and reorder buffer <b>32</b> via multiplexer <b>40</b>. Additionally, if the instructions entail one or more memory operations, decode units <b>20</b> dispatch the memory operations to load/store unit <b>26</b>. Each instruction is decoded into a set of control values for functional units <b>24</b>, and these control values are dispatched to reservation stations <b>22</b> along with operand address information and displacement or immediate data which may be included with the instruction. If decode units <b>20</b> detect a floating point instruction, the instruction is dispatched to FPU/MMX unit <b>36</b>.</p><p>When decode unit <b>20</b> outputs the decoded instructions, this may be referred to as \u201cdispatching\u201d the instructions. When instructions are dispatched to reorder buffer <b>32</b>, they are also copied in parallel into BBC <b>44</b>. BBC <b>44</b> stores the decoded instructions with an address tag comprising all or part of the fetch address that fetched the decoded instructions. In one embodiment, BBC <b>44</b> is fully associative and uses the entire fetch address as the tag. In another embodiment, BBC <b>44</b> is set associative (e.g., 4-way) and uses portions of the fetch address as the tag. This involves splitting the address into the following three portions: (1) the index, (2) higher tag bits, and (3) lower TAG bits. The index bits (used to index into BBC <b>44</b>) are bits selected from the middle of the fetch address. A tag comparison is performed for the higher and lower tag bits (offset). Thus, each basic block of instructions stored within BBC <b>44</b> has its own unique starting address and may be easily accessed.</p><p>BBSB <b>42</b> may be configured to have the same structure (e.g., addressing scheme) as BBC <b>44</b> and to receive the same fetch address information that BBC <b>44</b> receives from decode unit <b>20</b>. However, instead of storing basic blocks, BBSB <b>42</b> is configured to store information about the corresponding basic blocks in BBC <b>44</b>. For example, BBSB <b>42</b> may store predicted sequences of basic blocks and the addresses of all possible following basic blocks. It may also contain prediction information indicative of whether the corresponding branch instructions (that define the end of each basic block) will be taken or not taken. This prediction information may be used to select which basic block will be executed next.</p><p>In one embodiment, microprocessor <b>10</b> may employ branch prediction in order to speculatively fetch and or prefetch instructions subsequent to conditional branch instructions. Branch prediction unit <b>14</b> is included to perform such branch prediction operations. In one embodiment, branch prediction unit <b>14</b> is configured to store up to two branch target addresses for each 16 byte portion of each cache line in instruction cache <b>16</b>. Prefetch/predecode unit <b>12</b> determines initial branch targets when a particular line is predecoded. Subsequent updates to the branch targets corresponding to a cache line may occur due to the execution of instructions within the cache line. Instruction cache <b>16</b> provides an indication of the instruction address being fetched, so that branch prediction unit <b>14</b> may determine which branch target addresses to select for forming a branch prediction. Decode units <b>20</b> and finctional units <b>24</b> provide update information to branch prediction unit <b>14</b>. Because branch prediction unit <b>14</b> stores only two targets per 16 byte portion of the cache line, predictions for some branch instructions within the line may not be stored in branch prediction unit <b>14</b>. Decode units <b>20</b> detect branch instructions which were not predicted by branch prediction unit <b>14</b>. Functional units <b>24</b> execute the branch instructions and determine if the predicted branch direction is incorrect. The branch direction may be \u201ctaken\u201d, in which subsequent instructions are fetched from the target address of the branch instruction. Conversely, the branch direction may be \u201cnot taken\u201d, in which subsequent instructions are fetched from memory locations consecutive to the branch instruction. When a mispredicted branch instruction is detected, instructions subsequent to the mispredicted branch are discarded from the various units of microprocessor <b>10</b>. A variety of suitable branch prediction algorithms may be employed by branch prediction unit <b>14</b>.</p><p>Microprocessor <b>10</b> supports out of order execution, and thus employs reorder buffer <b>32</b> to keep track of the original program sequence for register read and write operations, to implement register renaming, to allow for speculative instruction execution and branch misprediction recovery, and to facilitate precise exceptions. A temporary storage location within reorder buffer <b>32</b> is reserved upon decode of an instruction that involves the update of a register to thereby store speculative register states. If a branch prediction is incorrect, the results of speculatively executed instructions along the mispredicted path can be invalidated in the buffer before they are written to register file <b>30</b>. Similarly, if a particular instruction causes an exception, instructions subsequent to the particular instruction may be discarded. In this manner, exceptions are \u201cprecise\u201d (i.e., instructions subsequent to the particular instruction causing the exception are not completed prior to the exception). It is noted that a particular instruction is speculatively executed if it is executed prior to instructions which precede the particular instruction in program order. Preceding instructions may be a branch instruction or an exception-causing instruction, in which case the speculative results may be discarded by reorder buffer <b>32</b>.</p><p>The instruction control values and immediate or displacement data provided at the outputs of decode units <b>20</b> are routed directly to respective reservation stations <b>22</b>. In one embodiment, each reservation station <b>22</b> is capable of holding instruction information (i.e., instruction control values as well as operand values, operand tags and/or immediate data) for up to three pending instructions awaiting issue to the corresponding functional unit. It is noted that for the embodiment of FIG. 2, each reservation station <b>22</b> is associated with a dedicated functional unit <b>24</b>. Accordingly, three dedicated \u201cissue positions\u201d are formed by reservation stations <b>22</b> and functional units <b>24</b>. In other words, issue position <b>0</b> is formed by reservation station <b>22</b>A and functional unit <b>24</b>A. Instructions aligned and dispatched to reservation station <b>22</b>A are executed by functional unit <b>24</b>A. Similarly, issue position <b>1</b> is formed by reservation station <b>22</b>B and functional unit <b>24</b>B; and issue position <b>2</b> is formed by reservation station <b>22</b>C and functional unit <b>24</b>C.</p><p>Upon decode of a particular instruction, if a required operand is a register location, register address information is routed to reorder buffer <b>32</b> and register file <b>30</b> simultaneously. Those of skill in the art will appreciate that the x<b>86</b> register file includes eight 32 bit real registers (i.e., typically referred to as EAX, EBX, ECX, EDX, EBP, ESI, EDI and ESP). In embodiments of microprocessor <b>10</b> which employ the x<b>86</b> microprocessor architecture, register file <b>30</b> comprises storage locations for each of the 32 bit real registers. Additional storage locations may be included within register file <b>30</b> for use by MROM unit <b>34</b>. Reorder buffer <b>32</b> contains temporary storage locations for results which change the contents of these registers to thereby allow out of order execution. A temporary storage location of reorder buffer <b>32</b> is reserved for each instruction which, upon decode, is determined to modify the contents of one of the real registers. Therefore, at various points during execution of a particular program, reorder buffer <b>32</b> may have one or more locations which contain the speculatively executed contents of a given register. If following decode of a given instruction it is determined that reorder buffer <b>32</b> has a previous location or locations assigned to a register used as an operand in the given instruction, the reorder buffer <b>32</b> forwards to the corresponding reservation station either: 1) the value in the most recently assigned location, or 2) a tag for the most recently assigned location if the value has not yet been produced by the functional unit that will eventually execute the previous instruction. If reorder buffer <b>32</b> has a location reserved for a given register, the operand value (or reorder buffer tag) is provided from reorder buffer <b>32</b> rather than from register file <b>30</b>. If there is no location reserved for a required register in reorder buffer <b>32</b>, the value is taken directly from register file <b>30</b>. If the operand corresponds to a memory location, the operand value is provided to the reservation station through load/store unit <b>26</b>.</p><p>In one particular embodiment, reorder buffer <b>32</b> is configured to store and manipulate concurrently decoded instructions as a unit. This configuration will be referred to herein as \u201cline-oriented\u201d. By manipulating several instructions together, the hardware employed within reorder buffer <b>32</b> may be simplified. For example, a line-oriented reorder buffer included in the present embodiment allocates storage sufficient for instruction information pertaining to three instructions (one from each decode unit <b>20</b>) whenever one or more instructions are dispatched by decode units <b>20</b>. By contrast, a variable amount of storage is allocated in conventional reorder buffers, dependent upon the number of instructions actually dispatched. A comparatively larger number of logic gates may be used to allocate the variable amount of storage. When each of the concurrently decoded instructions has executed, the instruction results are stored into register file <b>30</b> simultaneously. The storage is then free for allocation to another set of concurrently decoded instructions. Additionally, the amount of control logic circuitry employed per instruction may be reduced because the control logic is amortized over several concurrently decoded instructions. A reorder buffer tag identifying a particular instruction may be divided into two fields: a line tag and an offset tag. The line tag identifies the set of concurrently decoded instructions including the particular instruction, and the offset tag identifies which instruction within the set corresponds to the particular instruction. It is noted that storing instruction results into register file <b>30</b> and freeing the corresponding storage is referred to as \u201cretiring\u201d the instructions. It is further noted that any reorder buffer configuration may be employed in various embodiments of microprocessor <b>10</b>.</p><p>As noted earlier, reservation stations <b>22</b> store instructions until the instructions are executed by the corresponding functional unit <b>24</b>. An instruction is selected for execution if: (i) the operands of the instruction have been provided; and (ii) the operands have not yet been provided for instructions which are within the same reservation station <b>22</b>A-<b>22</b>C and which are prior to the instruction in program order. It is noted that when an instruction is executed by one of the functional units <b>24</b>, the result of that instruction is passed directly to any reservation stations <b>22</b> that are waiting for that result at the same time the result is passed to update reorder buffer <b>32</b> (this technique is commonly referred to as \u201cresult forwarding\u201d). An instruction may be selected for execution and passed to a functional unit <b>24</b>A-<b>24</b>C during the clock cycle that the associated result is forwarded. Reservation stations <b>22</b> route the forwarded result to the functional unit <b>24</b> in this case.</p><p>In one embodiment, each of the functional units <b>24</b> is configured to perform integer arithmetic operations of addition and subtraction, as well as shifts, rotates, logical operations, and branch operations. The operations are performed in response to the control values decoded for a particular instruction by decode units <b>20</b>. It is noted that FPU/MMX unit <b>36</b> may also be employed to accommodate floating point and multimedia operations. The floating point unit may be operated as a coprocessor, receiving instructions from MROM unit <b>34</b> and subsequently communicating with reorder buffer <b>32</b> to complete the instructions. Additionally, finctional units <b>24</b> may be configured to perform address generation for load and store memory operations performed by load/store unit <b>26</b>.</p><p>Each of the functional units <b>24</b> also provides information regarding the execution of conditional branch instructions to the branch prediction unit <b>14</b>. If a branch prediction was incorrect, branch prediction unit <b>14</b> flushes instructions subsequent to the mispredicted branch that have entered the instruction processing pipeline, and causes fetch of the desired instructions from instruction cache <b>16</b> or main memory. It is noted that in such situations, results of instructions in the original program sequence which occur after the mispredicted branch instruction are discarded, including those which were speculatively executed and temporarily stored in load/store unit <b>26</b> and reorder buffer <b>32</b>.</p><p>Results produced by functional units <b>24</b> are sent to reorder buffer <b>32</b> if a register value is being updated, and to load/store unit <b>26</b> if the contents of a memory location are changed. If the result is to be stored in a register, reorder buffer <b>32</b> stores the result in the location reserved for the value of the register when the instruction was decoded. A plurality of result buses <b>38</b> are included for forwarding of results from functional units <b>24</b> and load/store unit <b>26</b>. Result buses <b>38</b> convey the result generated, as well as the reorder buffer tag identifying the instruction being executed.</p><p>Load/store unit <b>26</b> provides an interface between functional units <b>24</b> and data cache <b>28</b>. In one embodiment, load/store unit <b>26</b> is configured with a load/store buffer having eight storage locations for data and address information for pending loads or stores. Decode units <b>20</b> arbitrate for access to the load/store unit <b>26</b>. When the buffer is full, the decode unit waits until load/store unit <b>26</b> has room for the pending load or store request information. Load/store unit <b>26</b> also performs dependency checking for load memory operations against pending store memory operations to ensure that data coherency is maintained. A memory operation is a transfer of data between microprocessor <b>10</b> and the main memory subsystem. Memory operations may be the result of an instruction which utilizes an operand stored in memory, or may be the result of a load/store instruction which causes the data transfer but no other operation. Additionally, load/store unit <b>26</b> may include a special register storage for special registers such as the segment registers and other registers related to the address translation mechanism defined by the x<b>86</b> microprocessor architecture.</p><p>In one embodiment, load/store unit <b>26</b> is configured to perform load memory operations speculatively. Store memory operations are performed in program order, but may be speculatively stored into the predicted way. If the predicted way is incorrect, the data prior to the store memory operation is subsequently restored to the predicted way and the store memory operation is performed to the correct way. In another embodiment, stores may be executed speculatively as well. Speculatively executed stores are placed into a store buffer, along with a copy of the cache line prior to the update. If the speculatively executed store is later discarded due to branch misprediction or exception, the cache line may be restored to the value stored in the buffer. It is noted that load/store unit <b>26</b> may be configured to perform any amount of speculative execution, including no speculative execution.</p><p>Data cache <b>28</b> is a high speed cache memory provided to temporarily store data being transferred between load/store unit <b>26</b> and the main memory subsystem. In one embodiment, data cache <b>28</b> has a capacity of storing up to sixteen kilobytes of data in an eight way set-associative structure. Similar to instruction cache <b>16</b>, data cache <b>28</b> may employ a way prediction mechanism. It is understood that data cache <b>28</b> may be implemented in a variety of specific memory configurations.</p><p>In one particular embodiment of microprocessor <b>10</b> employing the x<b>86</b> microprocessor architecture, instruction cache <b>16</b> and data cache <b>28</b> are linearly addressed. The linear address is formed from the offset specified by the instruction and the base address specified by the segment portion of the x<b>86</b> address translation mechanism. Linear addresses may optionally be translated to physical addresses for accessing a main memory. The linear to physical translation is specified by the paging portion of the x<b>86</b> address translation mechanism. It is noted that a linear addressed cache stores linear address tags. A set of physical tags (not shown) may be employed for mapping the linear addresses to physical addresses and for detecting translation aliases. Additionally, the physical tag block may perform linear to physical address translation</p><p>Basic Block Sequence Buffer (BBSB) and Basic Block Cache (BBC)</p><p>Turning now to FIG. 3, more details regarding the organization of one embodiment of BBSB <b>42</b> and BBC <b>44</b> are shown BBSB <b>42</b> comprises a plurality of storage lines <b>52</b>, each configured to store an address t