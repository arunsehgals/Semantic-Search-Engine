Technical Field</p><p>The present disclosure relates to a method and system for energy conservation in general and, in particular, to a method and system for reducing power consumption within a data processing system. Still more particularly, the present disclosure relates to a method and system for reducing power consumption of a non-blocking cache within a data processing system.</p><p>2. Description of the Related Art</p><p>Lightweight notebook computers have become increasingly popular in recent years as many people are buying a notebook computer instead of a desktop computer as their primary computer. One of the many advantages a notebook computer offers is portability, and frequently, this portability is enhanced by its ability to operate under battery power. Needless to say, it is preferable to have a battery-powered notebook computer operate under battery power for an extended period of time before the battery needs recharging or replacing. Accordingly, from a design standpoint, it is important to reduce the power consumption of a notebook computer in order to extend the time during which the computer operates before any recharging or replacing of battery is required.</p><p>A microprocessor within a notebook computer typically accounts for up to one-third of the notebook computer's total power budget, which is around 15 W. Hence, a microprocessor originally designed for high-end desktop computers, which requires a 5V power supply and dissipates up to 16 W, is probably not a suitable candidate for notebook computer applications. For a microprocessor specifically designed to be utilized in notebook computer applications, at least three criteria must be met. First, there must be low power dissipation during the normal operation of the microprocessor. Second, there must be features for power management within the microprocessor, such as dynamic power management, and third, the most important of all from a user standpoint, the processing power of the microprocessor must be comparable to its desktop counterparts.</p><p>One of such low-power microprocessor design is disclosed in U.S. Pat. No. 5,420,808, entitled \"Circuitry and Method for Reducing Power Consumption within an Electronic Circuit,\" and that patent is incorporated herein by reference thereto. The disclosed method under the above-referenced patent allows the microprocessor to consume less excess power without drastically sacrificing overall performance. In addition, the disclosed method is completely transparent to a user.</p><p>In light of U.S. Pat. No. 5,420,808, the present disclosure reveals a method for reducing power consumption of a non-blocking cache within a data processing system. The power consumption reduction method under the present disclosure may be implemented in any data processing system either independently or in conjunction with the method under U.S. Pat. No. 5,420,808. By implementing the method under the present disclosure in conjunction with the method under U.S. Pat. No. 5,420,808, an even lower power consumption level can certainly be achieved than utilizing the method under U.S. Pat. No. 5,420,808 alone.</p><h4>SUMMARY</h4><p>It is therefore an object of the present disclosure to provide an improved method and system for energy conservation.</p><p>It is another object of the present disclosure to provide an improved method and system for reducing power consumption within a data processing system.</p><p>It is yet another object of the present disclosure to provide an improved method and system for reducing power consumption of a non-blocking cache within a data processing system.</p><p>In accordance with a method and system of the present disclosure, a detection unit, having several index-matching bits, is associated with a cache memory within a data processing system. A determination is made as to whether or not there is a match in the cache memory, in response to an occurrence of a cache request while the cache memory is performing a linefill operation. In response to a determination that there is not a match for the cache request in the cache memory, another determination is made as to whether or not there is a match for the cache request with a block of information within the ongoing linefill operation. In response to a determination that there is a match for the cache request with a block of information within the ongoing linefill operation, one of the index-matching bits is set and clocks to the cache memory are turned off in order to reduce power consumption by the cache memory.</p><p>All objects, features, and advantages of the present disclosure will become apparent in the following detailed written description.</p><?BRFSUM description=\"Brief Summary\" end=\"tail\"?><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"lead\"?><h4>BRIEF DESCRIPTION OF THE DRAWINGS</h4><p>The disclosure itself, as well as an illustrative mode of use, further objects, and advantages thereof, will best be understood by reference to the following detailed description of an illustrative disclosure when read in conjunction with the accompanying drawings, wherein:</p><p>FIG. 1 is a conceptual block diagram of a processor in accordance with an exemplary embodiment of the present disclosure;</p><p>FIG. 2 is a block diagram of the organization of an 8-Kbyte instruction cache in according with an illustrative embodiment of the disclosure;</p><p>FIG. 3 is a timing diagram depicting the clock cycles of a non-blocking cache having a second cache request during a linefill operation under prior art;</p><p>FIG. 4 is a high-level logic flow diagram of a method for reducing power consumption in a non-blocking cache within a data processing system, in accordance with an exemplary embodiment of the present disclosure; and</p><p>FIG. 5 is a timing diagram depicting the clock cycles of a non-blocking cache having a second cache request during a linefill operation under the present disclosure.</p><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"tail\"?><?DETDESC description=\"Detailed Description\" end=\"lead\"?><h4>DETAILED DESCRIPTION OF AN ILLUSTRATIVE EMBODIMENT</h4><p>An illustrative embodiment under the present disclosure may be implemented on a variety of processors designed to have low power consumption. For the purpose of illustration, an exemplary embodiment as described below is implemented on one of the PowerPC\u2122 microprocessors manufactured by International Business Machines Corporation, which is intended for notebook computer applications.</p><p>Referring now to the drawings and in particular to FIG. 1, there is depicted a conceptual block diagram of processor 10 in accordance with an exemplary embodiment of the present disclosure. As shown, processor 10 includes a bus interface unit 12, an instruction cache 14, an instruction buffer 16, an instruction dispatch unit 18, a control unit 20, a fixed-point unit 22, a load/store unit 24, a floating-point unit 26, general purpose registers 28, floating-point registers 30, and a data cache 32.</p><p>Bus interface unit 12 is connected bi-directionally to a system bus 40 external to processor 10. A system memory 41 is also coupled to system bus 40. Instruction cache 14 is coupled to bus interface unit 12 through a data bus 42 and through an instruction bus 44. Instruction buffer 16 is coupled to instruction cache 14 through an instruction bus 46. Instruction dispatch unit 18 is coupled to instruction buffer 16 through an instruction bus 48. Instruction dispatch unit 18 is further coupled to instruction cache 14 through an instruction request bus 50. Fixed-point unit 22 is coupled to instruction dispatch unit 18 through an instruction bus 52. Load/store unit 24 is coupled to instruction dispatch unit 18 through an instruction bus 54. Floating-point unit 26 is coupled to instruction dispatch unit 18 through an instruction bus 56.</p><p>Moreover, fixed-point unit 22 is coupled to general purpose registers 28 through a data bus 58. Floating-point unit 26 is coupled to floating-point registers 30 through a data bus 60. Also, load/store unit 24 is coupled to general purpose registers 28 through a data bus 58. Load/store unit 24 is further coupled to floating-point registers 30 through a data bus 60. Data cache 32 is coupled to load/store unit 24 through a data bus 64. General purpose registers 28 are coupled to data cache 32 through a data bus 66. Floating-point registers 30 are also coupled to data cache 32 through a data bus 66. General purpose registers 28 are coupled to fixed-point unit 22 through a data bus 58. Floating-point registers 30 are also coupled to floating-point unit 26 through a data bus 70. Data cache 32 is coupled to bus interface unit 12 through a data bus 72 and through an address bus 74.</p><p>In addition, processor 10 is connected to an external system clock line CLK<sub>SYS</sub>, from which processor 10 receives its clock signals. Further, processor 10 is connected to a DC power source 33, such as a battery or an AC-to-DC converter, from which processor 10 receives its power. For clarity, the distribution of power from DC power source 33 throughout processor 10 is not shown in FIG. 1.</p><p>Processor 10 is a CMOS circuit having multiple interconnects. CMOS circuits do not consume significant power if signals on interconnects are not actively transitioning between various levels. Thus, when these interconnects are held in a steady state, power consumption of processor 10 can be reduced. For example, power consumption may be reduced by holding the latch data of processor 10. Nevertheless, even if the latch data are held constant, the local clock regenerators continue to switch a significant amount of capacitance through clock signal lines distributed throughout processor 10 to various latches. Accordingly, local clock regenerators result in a significant amount of power consumption within processor 10.</p><p>As it is well-known in the art that the power consumptions in various sections of processor 10 can be reduced if certain power-saving conditions are satisfied. More particularly, a section's power consumption can be reduced by reducing a clock signal transition from the section's local clock regenerators to a zero frequency. In this manner, the section's functional logic is stopped, and accordingly, the power consumption of the section's functional logic and of the section's clock signal lines distributed to latches becomes negligible.</p><p>Thus, processor 10 is preferably partitioned for the clock regenerators, so that latches sharing a common power-saving hold condition are grouped together. Such grouping is a primary power reduction aspect of processor 10. By grouping clock regenerators and by detecting power-saving hold conditions, power is reduced on processor 10 because a majority of interconnects do not transition between levels unnecessarily.</p><p>Also, in a significant power-reduction aspect of the exemplary embodiment, instruction cache 14 includes a detection unit 34 and data cache 32 includes a detection unit 38. Although detection units 34 and 38 are shown as being integral with other units of processor 10, detection units 34, 38 can be defined separately from the other units and yet still be integral with processor 10.</p><p>Detection unit 34 is coupled to lookup logic in instruction cache 14 through a hold line 80a. Detection unit 34 is further coupled to bus interface unit 12 through a wakeup line 80b. Also, detection unit 34 is coupled to certain buffer locations of instruction buffer 16 through a hold line 80c. Within detection unit 34, there are several index-matching bits 34a.</p><p>Detection unit 38 is coupled to lookup logic in data cache 32 through a hold line 84a. Further, detection unit 38 is coupled to bus interface unit 12 through a wakeup line 84b. Also, detection unit 38 is coupled to fixed-point unit 22 through a hold line 84c, and to floating-point unit 26 through a hold line 84d. Within detection unit 38, there are several index-matching bits 38a.</p><p>During operation, instruction dispatch unit 18 requests an output of instruction information from instruction cache 14 through instruction request bus 50. If instruction cache 14 contains a requested instruction, then instruction cache 14 outputs the requested instruction to instruction buffer 16 through instruction bus 46. After instruction buffer 16 receives the requested instruction from instruction cache 14, instruction dispatch unit 18 obtains the requested instruction from instruction buffer 16 through instruction bus 48.</p><p>If instruction cache 14 does not contain a requested instruction, then a linefill operation must be performed in order to obtain the requested instruction from system memory 41 via external system bus 40. A significant period of time may elapse after instruction cache 14 sends the requested instruction to bus interface unit 12 and before the critical doubleword of the cache line returns. Also, there are significant time lapses between each beat of returning information subsequent to the critical doubleword.</p><p>Similarly, if data cache 32 does not contain data requested by load/store unit 24 for fixed-point unit 22 (or for floating-point unit 26), then a linefill operation must be performed in order to obtain the requested instruction from system memory 41 via external system bus 40. A significant period of time may elapse after data cache 32 sends the requested instruction to bus interface unit 12 and before the critical doubleword of the cache line returns. Also, there are significant time lapses between each beat of returning information subsequent to the critical doubleword.</p><p>With reference now to FIG. 2, there is depicted a block diagram of the organization of an 8-Kbyte instruction cache 14 according to an illustrative embodiment of the disclosure. Instruction cache 14 is configured as a two-way cache--way 0 and way 1, with each way having 128 cache lines, from line 0 to line 127. Each cache line comprises an address tag 80, one valid bit 82, and instruction block 84. Instruction block 84 is 32 bytes (or 4 doublewords) wide while address tag 80 is only 20 bits wide.</p><p>Each cache line is indexed by bits 20-26 of an address 30, and each byte within the cache line is indexed by bits 27-31 of address 30. In addition, address tag 80 within each cache line contains an address tag that is utilized for comparison with bits 0-19 of address 30 in order to determine whether there is a cache \"hit\" or \"miss.\" Incidentally, a match between address tag 80 in one of ways 0 or 1 and bits 0-19 of address 30 means a cache \"hit.\" Further, valid bit 82 is for indicating whether that particular cache line is valid or not. Typically, a \"1\" means the instruction in the cache line is valid while a \"0\" means the instruction in the cache line is not valid, though a reverse assignment is also acceptable. The organization of data cache 32 is similar to that of instruction cache 14.</p><p>Referring now to FIG. 3, there is depicted a timing diagram of the cache clocks of a non-blocking cache having a new cache request during a linefill operation under prior art. During the linefill operation, there is already a provision under the prior art to turn off the clocks of the non-blocking cache when the cache is waiting for the critical doubleword (or critical word, depending on cache architecture) of the instruction or data from the bus interface unit, in order to reduce power consumption by the idle cache. During this time, a new request to the cache may occur. For a blocking cache, because it cannot process any other request during a linefill operation, the new cache request is not an issue. However, a non-blocking cache still has to attend to the new cache request. When there is a cache \"miss\" to the new cache request, the cache must continue to check whether or not the information requested by the new cache request is in any one of the incoming doubleword of the ongoing linefill operation. Hence, the clocks to the cache cannot be turned off between incoming data during the linefill operation, such as cycles 3, 5, 7, etc. As such, the power reduction scheme for the cache as originally cont