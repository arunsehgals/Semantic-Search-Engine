and memory 20 simultaneously. The Tag rams 16 provide a TAG, (the upper address bits of the memory request) which is latched in tri-state latch 28a, and provided to the secondary cache tag comparator 30. As part of the probe, the tag comparator 30 compares the data received from latch 28a against the upper address bits of the memory request provided from address queue 32. The HIT status is provided to secondary cache control state machine 38 on line 31.</p><p>In the event of a HIT, correct data has already been received during the probe of the cache tags 16 and secondary cache data RAMS 18, and the secondary cache control state machine 38 asserts the Next Address\\Command signal on line 41 to the address and command queue 32 to receive the next memory address and command.</p><p>In the event of a miss (or the absence of a HIT signal in a predetermined cycle), the secondary cache control state machine 38 asserts the Select Replay signal on line 42 to the mux 32a for providing a replay address, stored in latch 32c. In addition, a memory command is provided on line 38a to the DRAM control state machine 36. Once the command for memory 20 has been initiated, the secondary cache control state machine 38 waits for the CAS HOLD DONE signal from the memory control state machine 36 before asserting the Next Address\\Command signal on line 41 to the address and command queue 32. The CAS HOLD DONE signal indicates that the Column Address Strobe (CAS) hold time has elapsed in the case of a miss in the cache.</p><p>Generally, because instructions typically access memory data in order, and due to the delay with obtaining data from an external memory device, (secondary cache or main memory), each memory transaction requests a block of data. A block of data is generally a group of longwords stored in consecutive memory addresses. The CPU 12 initiates a command, for example `Block Fill`, which indicates that a block of data is required from external memory, where the first quadword is at an address provided in the `FILL` instruction, and other required data are located at consecutive longword displacements from the original address. The block of data is provided to the primary cache of the CPU 12.</p><p>Because block addressing uses sequential addresses, the address bits which differ for each memory access are only the address bits which correspond to the bits associated with the block index. For example, with a block size of 4 quadwords, only bits 4 and 3 change value during the block access. Such an arrangement is shown below in Table 1, using a 15 bit address.</p><p></p><pre listing-type=\"tabular\" xml:space=\"preserve\"><!--Greenbook tabular data-->__________________________________________________________________________\nAddress:                                                                  \n     15                                                                   \n       14                                                                 \n         13                                                               \n           12                                                             \n             11                                                           \n               10                                                         \n                 9 8 7 6 5 4 3 2 1 0                                      \n__________________________________________________________________________\nQW0  1 1 1 1 1 1 1 1 1 1 1 0 0 X X X                                      \nQW1  1 1 1 1 1 1 1 1 1 1 1 0 1 X X X                                      \nQW2  1 1 1 1 1 1 1 1 1 1 1 1 0 X X X                                      \nQW3  1 1 1 1 1 1 1 1 1 1 1 1 1 X X X                                      \n__________________________________________________________________________\n</pre><p>Thus, only two bit of address, bits 4 and 3, are changed during a block access with a block size of four quadwords. Because it is a quadword access (8 bytes), the lower bits of the address &lt;2:0&gt; are not required to perform the memory access, and are generally decoded into a mask of 8 bits which is used for selecting the appropriate bytes inside the CPU 12.</p><p>If the block size is larger than 4 quadwords, generally the number of bits of the address which change during the block address is given by the function log<sub>2</sub> (N), where N is the number of quadwords in the block.</p><p>By replicating the bits of the address which correspond to the block index (in this example, bit 4 and 3) to provide a dedicated number of address bits for memory, the address provided to the memory device 20 remains stable while the cache address index is advanced for the next transaction.</p><p>Referring again to FIG. 2, a preferred embodiment of the memory controller 14 additionally includes a flow through latch 44 for storing the block index bits &lt;4:3&gt; of each address provided to memory. Address bits &lt;15:3&gt; for a cache and memory access are provided from mux 32b and stored in flip flop 42. The address is shown here to include 12 bits, however, the number of bits for each address will be a function of the size and layout of the cache and memory. The address stored in flip-flop 42 is provided to the cache and memory address pins on bus 15a. Here, the lower two bits, &lt;4:3&gt; on bus 15b are dedicated to providing the block index address bits &lt;4:3&gt; to the secondary cache 18 and cache tag RAM 16 of FIG. 1.</p><p>The lower bits &lt;4:3&gt; on bus 15b are further provided to a flow through latch 44. Latch 44 is `slaved` to flip-flop 42, that is it is enabled to allow bits &lt;4:3&gt; from address bus 15b to flow through to bus 15c when either the HIT signal is asserted or a CAS HOLD DONE signal is asserted. Thus, this signal indicates that the data was obtained from memory, and the memory address may be changed to handle the next read or write request.</p><p>As shown in FIG. 2, NOR gate 43 is used to provide the enabling signal to the flow through latch 44. Although a NOR gate has been shown, another circuit providing a similar function may-also be used.</p><p>Referring now to FIG. 3, a state diagram of the secondary cache control state machine 38 is shown to include a refresh state 50. The refresh state is entered when it is necessary to perform a refresh of the DRAMs in main memory 20. Generally, the refresh control includes a refresh count register and a refresh counter. The refresh count register is loaded by the user, and indicates the number of clock cycles between refreshes. This value is dependant upon the cycle time of the CPU and the characteristics of the DRAM.</p><p>Once the DRAMs have been refreshed, the secondary cache control state machine 38 enters a ready state 52, where it waits for commands from address and command queue 32 (FIG. 2). The types of commands include Direct Memory Access (DMA) commands, I/O commands, or memory commands. Once a command is received, the state machine 38 transitions to a decode state 56, which transitions to either a Memory command state 58 (for memory commands), a DMA1 state 60 (for DMA commands), or an I/O state 62 for I/O commands.</p><p>In memory command state 58, control signals are provided to the secondary cache 18 and tags 16 by memory controller 14 to enable the state machine to transition to the probe state 64. During the probe, as described previously, the cache tag RAMs 16 (FIG. 1) and the secondary cache data RAMs 18 (FIG. 1) are accessed by asserting the chip select signal (C<sub>--</sub> CS) and the output enable signal (C<sub>--</sub> OR). The data and tag are transmitted by secondary cache 18 and tags 16 and received and stored in CPU 12. Once the data has been received by the CPU 12, the state machine transitions to Tag check state 66. During Tag check state, the tag received from tag RAM 16 (FIG. 1) is compared against the upper address bits of the address provided by address and command queue 32. If there is a match between the address bits and the provided tag (a HIT), and if the command is a read command, then it is determined that correct data was received during the probe, and the state machine transitions to error check state 67. During error check state 67, the parity of the received data is verified, and the state machine transitions back to memory command state 58 to receive the next memory command.</p><p>If there is a match between the upper address bits provided by address and command queue 32 and the provided tag, and the command is a write command, the state machine transitions to the cache write state 68. During cache write state, the chip select signal (C<sub>--</sub> CS) and the write enable signal (C<sub>--</sub> WE) to the secondary cache are asserted, and data provided by the CPU 12 on data bus 15d is written to the cache data RAMs. After assertion of the control signals, the state machine transitions to the write transaction state 70, during which the signals remain asserted for the required time period to perform the cache write operation. Once the write operation is complete, the state machine transitions back to the memory command state 58 to receive the next memory command.</p><p>Because the secondary cache here is a write-back cache, the data written to the secondary cache RAMs 18 is not written simultaneously to memory 20. Rather, a bit indicating that the data at the memory address has been modified is asserted. When the CPU 12 requires use of a location in secondary cache RAM 18 for a new memory address, the modified data at the required location is stored in memory 20 before the data from the new memory address is stored at the location of the secondary cache RAM 18.</p><p>If the upper address bits provided by address queue 32 and the provided tag do not match, the state machine proceeds to either the DRAM read state 72 (for read or read modify write operations) or to the DRAM write state 74. During these states, the secondary cache control state machine 38 provides the appropriate memory command on line 38a to the DRAM control state machine 36, which performs the operation, and upon completion returns control to the secondary cache control state machine 38, through the use of the signal CAS<sub>--</sub> HOLD<sub>--</sub> DONE. If there is a read modify write operation with a cacheable address and a masked write, the state machine transitions from DRAM read state 72 to cache write state 68, to write transaction state 70 then to memory command state 58 to receive the next memory command. Since the system described here is a write-back cache, the modified data written to the secondary cache RAMs 18 is later written back to the memory device 20 when space is needed in the cache RAMs 18 by the CPU 12.</p><p>For either a read or a write command, the state machine transitions to cache write state 68 in order to update the secondary cache data RAMs 18 and cache tag RAMs 16 with the correct data from main memory 20 for the given memory address provided on address bus 15a. The cache write state 68 then updates the secondary cache as described previously.</p><p>Referring now to FIG. 4, a timing diagram illustrating the use of the memory controller 14 of FIG. 2 is described with reference to FIG. 2. For illustration purposes, only the values of the lower two bits of the cache address bus 15b and the memory address bus 15c are shown, because, as described previously, during a sequential block access the other bits do not change for each memory access of the block.</p><p>At time T0, the address bits for accessing Quadword 0 are provided on Cache bus 15b and memory bus 5c (FIG. 2). A setup time characteristic is required to be satisfied for accessing both the Cache tag RAMs 16 and the secondary Cache Data RAMs 18. The setup time characteristic is the amount of time that the address on address bus 15a and 15b must be stable before data from the cache tag RAMs 16 and the cache data RAMs 18 is latched. At time T1, the output enable, (here shown low-asserted) in asserted and the data is provided on data bus 15d of FIG. 1.</p><p>At time T2, secondary cache address bits &lt;4:3&gt; on bus 15b switch to enable access of Quadword 1, while memory address bits &lt;4:3&gt; on bus 15c remain stable. Also at T2, a `HIT` signal is provided, indicating that the data is available in the cache. This `HIT` signal enables the latch 44 of FIG. 2 to pass the lower address bits for accessing Quadword 1 from bus 15b to memory address bus 15c.</p><p>At time T3, the data for Quadword 1 is provided, and at time T4 the address on bus 15b switches to enable access of Quadword 2, while the address on bus 15c remains stable. Here, the absence of a HIT signal at time T4 indicates that there has been a `miss` in the cache.</p><p>The secondary cache control state machine 38 uses this absence of the HIT signal to provide the address from replay latch 32c (FIG. 2) to flip-flop 42 and consequentially secondary cache address bus&lt;4:3&gt;. During this time period, memory address bus 15c remains stable, and thus the set-up time characteristic for addressing memory 20 begins to be satisfied during cycle T3, and continues to accrue even though the address to the secondary cache data RAMs 18 changes during cycles T4 and T5.</p><p>After the setup time for the memory address has been satisfied, at time T6, the CAS signal is asserted to memory 20, and the data is provided on data bus 15d during cycles T6 and T7. In the case of a read miss in the secondary cache RAMs 18, the secondary cache memory controller 38 writes the data from data bus 15d into the secondary cache RAMs as shown during T6 by asserting the C<sub>--</sub> WE signal, and in addition, the correct TAG is provided on bus 15f, and the secondary cache TAG RAMs 16 are also updated with the correct TAG.</p><p>Subsequently, at T9 the cache reference for Quadword 2 is completed. Thus, such an arrangement allows for closely piplined cache accesses with only a minimal delay due to memory accesses as a result of a miss in the cache. In addition, such an arrangement allows for minimal duplication of pins on the package of the processor 12.</p><p>Referring again to FIG. 2, certain modifications can be made to the preferred embodiment of the memory controller 14 in an effort to save logic gates in the design. These modifications, described below, incorporate the basic functions of the memory controller 14, although providing reduced performance for main memory accesses relative to the preferred embodiment.</p><p>In one embodiment, the replay flip-flop 32c, and the multiplexer 32a are removed from the memory controller circuit 14. Due to the lack of replay flip-flop 32c, the address on address bus 15a and 15b must remain stable until a determination of the `HIT` status is made. Because the address remains stable for this extended period, both the secondary cache data RAMs 18 and the memory 20 can be accessed using identical addresses. As a result, the latch 44, NOR gate 43, and pins for bus 15c are no longer necessary for memory controller 14, and the bits &lt;4:3&gt; of the address for main memory 20 are driven from the cache address bus 15b.</p><p>Consequently, this embodiment provides both a reduced pin count and a reduced gate count, although providing reduced performance for secondary cache accesses as compared to the preferred embodiment as described with reference to FIGS. 2, 3 and 4. However, such a design may be desirable in certain applications where there are fewer available gates and pins, and the delay associated with memory references is less critical.</p><p>The effect of the operation of memory controller 14 due to the removal this logic is shown in FIG. 5. At T0, the address for the cache is transmitted on address bus 15a to the cache tag RAMs 16, the cache data RAMs 18, and the memory 20.</p><p>The data and tag are provided from cache data RAMs 18 and cache tag RAMs 16 on Bus 15d during clock cycles T3 and T4. At T1, the data and tag are latched in the CPU 12 and, during T1, a comparison is made against the data from cache tag RAMs 16 and the upper portion of the memory address provided by the CPU to determine if the address portions match. At time T2, if a match has occurred, the HIT signal is asserted, and the CPU is able to proceed with the next cache access. Thus, at time T3, the index address for the next Cache access appears on the address line 15a.</p><p>Starting at time T3, an example of a secondary cache `miss` situation is shown. At time T3, the address is placed on address line 15a and at time T4, after setup time characteristics have been satisfied, the Output Enable signal is asserted. The data from cache data RAMs 18 and the tag from cache tag RAMs 16 are fed into the memory controller 14 and, at T4, the memory controller 14 compares the received tag against the upper portion of the memory address. It can be seen that at T5 there is no assertion of the HIT signal, indicating that the data obtained from the cache is not the desired data.</p><p>The memory controller 14 uses the absence of the HIT signal during this time interval to assert the control signals to start access of memory 20. If the memory is operating in page-mode, the column address has been asserted on the address line 15a for a sufficient time to satisfy the set-up time for the Column Strobe signal (CAS). Thus, when no HIT signal appears at time T5, at T6 the memory controller 14 asserts the CAS signal, and the memory access is started.</p><p>As describ