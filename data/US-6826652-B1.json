First, the RAM set cache (mapped to a contiguous block of main memory addresses) can significantly improve the operation of a processing device performing real-time operations, since a desired block of code can be stored in the RAM set cache for fast retrieval. Second, there is no extra penalty for accessing a larger data memory for a RAM set cache, as long as the access time of the RAM set is not bigger than the access time of the standard cache. Third, the addition of one or more RAM set caches can be provided with a minimal amount of circuitry over a conventional cache. Fourth, the RAM set caches can be configured in a very flexible manner with other caches, such as a set associative or direct map cache, as desired. Fifth, the RAM set cache provides advantages over a local RAM, because a separate mechanism for loading the data memory is not necessary for the RAM set cache and no specific address decoding in serial with the memory access time is required. Sixth, the cache can be controlled by the OS or other software in the same manner as an ordinary cache\u2014loading, flushing, line invalidation, and so on, can be performed by the software without knowledge of the specific architecture of the cache, or with minor modifications to a driver for the OS.</p><?BRFSUM description=\"Brief Summary\" end=\"tail\"?><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"lead\"?><h4>BRIEF DESCRIPTION OF THE SEVERAL VIEWS OF THE DRAWINGS</h4><p>For more complete understanding of the present invention, and the advantages thereof, reference is now made to the following descriptions taken in conjunction with the accompanying drawings, in which:</p><p>FIG. 1 illustrates a block diagram of a processing device incorporating a cache;</p><p>FIG. 2 illustrates a block diagram of a preferred embodiment of a cache architecture;</p><p>FIG. 3 is a diagram showing the mapping of a portion of main memory onto a RAM set cache; and</p><p>FIG. 4 illustrates a flow diagram describing operation of the hit/miss logic of FIG. <b>2</b>.</p><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"tail\"?><?DETDESC description=\"Detailed Description\" end=\"lead\"?><h4>DETAILED DESCRIPTION OF THE INVENTION</h4><p>The present invention is best understood in relation to FIGS. 1-4 of the drawings, like numerals being used for like elements of the various drawings.</p><p>FIG. 1 illustrates a block diagram of a processing device <b>10</b>. Processing device <b>10</b> includes a processing core <b>12</b>, data memory <b>14</b>, instruction cache <b>16</b>, and subsystem memory interface <b>18</b>. Subsystem memory interface <b>18</b> interfaces with main memory <b>20</b>, which is typically an external memory.</p><p>As described in greater detail below, in the preferred embodiment, the instruction cache is a 3-way cache with one cache way being a \u201cRAM set\u201d cache memory. The RAM set cache is designed to cache a contiguous block of memory starting from a chosen main memory address location. The other two cache ways can be configured as RAM set cache memories, or use another architecture. For example, the instruction cache <b>16</b> could be configured as one RAM set cache and a 2-way set associative cache.</p><p>In operation, the processing core <b>12</b> accesses main memory <b>20</b> within a given address space. If the information at a requested address in main memory is also stored in the instruction cache <b>16</b>, the data is retrieved from the instruction cache. If information for the requested address is not stored in the instruction cache, the information is retrieved from the main memory <b>20</b> and the instruction cache is updated with the retrieved information.</p><p>FIG. 2 illustrates a more detailed block diagram of the instruction cache <b>16</b>, in an embodiment with a RAM set cache and a two-way set as associative cache.</p><p>A cache controller <b>22</b> controls operation of the instruction cache <b>16</b>. Cache controller <b>22</b> includes four status bits: RAM_fill_mode <b>24</b>, Cache_Enable <b>26</b>, DM/2SA <b>28</b> and Full_RAM_base <b>30</b>. Cache controller <b>22</b> is coupled to Full_Set_Tag registers <b>32</b> (individually referenced as registers <b>32</b><sub>1 </sub>through <b>32</b><sub>3</sub>), Global_Valid bits <b>34</b> (individually referenced as bits <b>34</b><sub>1 </sub>through <b>34</b><sub>3</sub>), tag memories <b>36</b> (individually referenced as tag memories <b>36</b><sub>2 </sub>and <b>36</b><sub>3</sub>), valid entry bit arrays <b>37</b> (individually referenced as bit arrays <b>37</b><sub>1 </sub>through <b>37</b><sub>3</sub>) and data arrays <b>38</b> (individually referenced as data arrays <b>38</b><sub>1 </sub>through <b>38</b><sub>3</sub>). Comparators <b>40</b> (individually referenced as comparators <b>40</b><sub>1 </sub>through <b>40</b><sub>3</sub>) are coupled to respective Full_Set_Tag registers <b>32</b>. Comparators <b>42</b> (individually referenced as comparators <b>42</b><sub>2 </sub>and <b>42</b><sub>3</sub>) are coupled to respective tag memories <b>36</b>. Output buffers <b>44</b> (individually referenced as buffers <b>44</b><sub>1 </sub>through <b>44</b><sub>3</sub>) are coupled to respective data arrays <b>38</b>. Hit/Miss logic <b>46</b> (individually referenced as logic <b>46</b><sub>1 </sub>through <b>46</b><sub>3</sub>) is coupled to comparators <b>40</b>, global valid bits <b>34</b>, valid bits <b>37</b>, RAM_fill_mode bit <b>24</b> and Cache_Enable bit <b>26</b>.</p><p>In operation, instruction cache <b>16</b> is configured using the control bits <b>24</b>, <b>26</b>, <b>28</b> and <b>30</b>. The Cache_Enable <b>26</b> allows the instruction cache to be enabled or disabled, as in standard cache architecture. If the instruction cache <b>16</b> is disabled (Cache Enable=0), instruction read accesses are performed on the main memory <b>20</b> via the subsystem memory interface <b>18</b>, without using the instruction cache <b>16</b>. If the instruction cache is enabled (Cache_Enable=1), instructions are executed from the instruction cache <b>16</b>, in cases where such instructions are present in the instruction cache <b>16</b>. If a miss occurs, a line (for example, 16 bytes) is fetched from main memory <b>20</b> and provided to the core <b>12</b>. This is also standard cache behavior.</p><p>The size of the data array <b>38</b><sub>1 </sub>can be different than the size of the data arrays <b>38</b><sub>2,3 </sub>for the other ways of the cache. For illustration purposes, it will be assumed that data arrays <b>38</b><sub>2 </sub>and <b>38</b><sub>3 </sub>are each 8 Kbytes in size, configured as 512 lines, with each line holding eight two-byte instructions. Data array <b>38</b><sub>1 </sub>is 16 Kbytes in size, configured as 1024 lines, each line holding eight two byte instructions. ADDR[L] is used to address one line of the data array <b>38</b> and valid bit array <b>37</b> (and tag memory <b>36</b>, where applicable). Accordingly, for the 1024-line first way, ADDR[L] will include bits [<b>13</b>:<b>4</b>] of an address from the core. For the 512-line second and third ways, ADDR[L] will include bits [<b>12</b>:<b>41</b>] of an address from the core. ADDR[H] defines which set is mapped to a line. Hence, assuming a 4 Gbyte (2 Gword) address space, ADDR[H] uses bits [<b>31</b>:<b>14</b>] of an address from the core for the first way and uses bits [<b>31</b>:<b>13</b>] for each of the second and third ways of the cache <b>16</b>.</p><p>The tag memories <b>36</b> and comparators <b>42</b> are used for a 2-way set associative cache. When the core <b>12</b> performs a memory access, the tag memories <b>36</b> are accessed at the low order bits of the address (ADDR[L]). The tag memory locations store the high order address bits of the main memory address of the information stored in a corresponding line of the data array <b>38</b>. These high order address bits are compared with the high order address bits (ADDR[H]) of the address from the core <b>12</b>. If the ADDR[H] matches the contents of the tag memory at ADDR[L], a hit occurs if the valid bit associated with the low order bits (V[ADDR[L]]) indicates that the cache entry is valid. If there is a cache hit, the data from the corresponding data array <b>38</b> at ADDR[L] may be provided to the core <b>12</b> by enabling the proper output buffer <b>44</b>. As described below, data from the 2-way cache is presented to the core <b>12</b> only if there is a miss in the RAM set cache. By itself, the operation of the 2-way set associative cache and the direct map cache can be conventional and is not affected by the RAM set cache. Other cache techniques could also be used in conjunction with the RAM set cache.</p><p>The RAM set cache stores a contiguous block of main memory <b>20</b> starting at an address defined by the Full_set_tag register <b>32</b> for the RAM set. This block of information is mapped to the corresponding data array <b>38</b> of the RAM set. Only the high order bits of the starting address are stored in the Full_set_tag register <b>32</b>. FIG. 3 illustrates this mapping for a single RAM set. As shown, the contents of Full_set_tag register <b>32</b><sub>1 </sub>defines the starting address for a contiguous block of memory cached in data array <b>38</b><sub>1</sub>.</p><p>A RAM set miss occurs when the high order bits of the address from the core <b>12</b> do not match the contents of the Full_set_TAG register <b>32</b> or the global valid bit equals \u201c0\u201d. In either case, when there is a RAM set miss, the instruction cache <b>16</b> behaves like a normal 2-way cache logic\u2014if there is a hit in the 2-way. cache, then an instruction is presented to the core <b>12</b> from the 2-way set associative cache; otherwise the instruction is retrieved from main memory <b>20</b>.</p><p>A RAM set hit situation occurs when the high order bits of the address from the core <b>12</b> match the contents of the Full_set_TAG register <b>32</b> and the global valid bit equals \u201c1\u201d (the setting of the global valid bit is described in greater detail hereinbelow). The RAM set comparison has the highest priority by default. A hit situation indicates that the requested instruction is mapped to the RAM set. If the Valid entry bit <b>37</b> corresponding to the line containing the instruction is set to \u201c1\u201d, the logic <b>40</b> generates a hit-hit signal, 