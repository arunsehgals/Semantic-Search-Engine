ata to and from processor core 102 by bus 109. Likewise, control information is passed between control logic 104 and system bus controller 103 by bus 110.</p><p>Data array 105 operates to store cached data or instructions. Directory array 106 operates in conjunction with data array 105 to store address and control information pertaining to each of the data entries in data array 105. Such address and control information stored in directory array 106 might include such typical information as tag bits, dirty bits, and valid bits.</p><p>Data path 107 operates to control the flow of data or instructions to and from system bus controller 103 by bus 113, to and from processor core 102 by bus 111, and to and from data array 105 by bus 115. Address path 108 operates to control the flow of address information to and from system bus controller 103 by bus 114, to and from processor core 102 by bus 112, and to and from directory array 106 by bus 116.</p><p>The typical approach for cache locking, as briefly described above with respect to FIG. 2, uses a lock bit to prevent any allocation in the locked section. Portions of data array 105 may be locked by asserting a lock bit in a control register within control logic 104.</p><p>The flow diagram in FIG. 4 further illustrates this typical approach. In step 401, a cacheable access is received from processor core 102. Essentially, processor core 102 is accessing an instruction or data. In accordance with the typical operation of a cache, cache 101 first determines in step 402 whether or not the instruction or data currently resides in valid form in data array 105. If so, the process moves to step 403 where no allocation is necessary and the hit level specifies the level accessed. The process then ends in step 411.</p><p>If, however, in step 402 there is a miss on the accessed instruction or data, the process then moves to step 404 to determine whether or not any portions of array 105 are locked. If so, the process moves to step 408 to determine whether or not there are any invalid entries in the unlocked region of the row indexed by the applied address. If there are not, the process proceeds to step 409 to allocate an entry in a level specified by some function of the replacement algorithm and cache lock bit implemented within cache 101. Since the cache lock mechanism has been activated, the replacement algorithm is forced to point to an unlocked portion of array 105. An entry in the unlocked portion will then be allocated and directory array 106 updated appropriately.</p><p>If, however, in step 408, there does exist an invalid entry in the unlocked region of the row indexed by the applied address, the process proceeds to step 410 to allocate an invalid entry in the unlocked region. Because there is a cache lock enforced, an invalid entry residing in the unlocked region of array 105 is allocated.</p><p>If in step 404, a cache lock has not been activated, the process will proceed to step 405 to determine whether there are any invalid entries in the row indexed by the applied address. If yes, the process proceeds to step 407 to allocate one of these invalid entries, and updates directory array 106 appropriately. If in step 405 there are no invalid entries, then the process will proceed to step 406 to allocate an entry in a level specified by some function of the replacement algorithm. Thus, any level may be used for this allocation.</p><p>As can be seen by the process illustrated with respect to FIG. 4, allocation of entries in a locked portion of cache 101 is not possible.</p><p>Referring next to FIG. 3, there is a depiction of an implementation of one embodiment of the present invention with respect to a cache locking mechanism. With such an approach, the lock bit mentioned above is used to force any de-allocation (i.e., any replacement) of a cache entry to the unlocked portion of cache 101. Further, the present invention permits allocation of cache entries in a locked region provided that there are any invalid entries existing within this locked region. Since de-allocation can only occur in the unlocked region, locked entries are preserved.</p><p>Referring next to FIG. 5, there is a flow diagram of the process of the present invention, which may be implemented as logic circuitry within control logic 104. First, in step 501, a cacheable access is received from processor core 102. If there is a determination in step 502 that there is a hit in cache 101, the process proceeds to step 503 where no allocation is necessary and the hit level specifies the level accessed.</p><p>If, however, in step 502 there is a miss in cache 101 with respect to the accessed instruction or data, the process proceeds to step 504 to determine whether or not there are any invalid entries in the row indexed by the applied address. If there are, the process proceeds to step 505 to allocate one of these invalid entries. A cache level specified is a function of level validity, i.e., an allocation can use any invalid level. Also, appropriate information in directory array 106 is modified.</p><p>As can be seen, allocation of entries in data array 105 is performed regardless of whether or not the entry resides within a locked portion. The process of the present invention is concerned only with whether or not there are any invalid entries for an allocation.</p><p>If in step 504 there are no invalid entries designated, then the process proceeds to step 506 to determine whether or not the cache is locked. If the cache is locked, the process proceeds to step 508 to allocate an entry specified by a replacement algorithm. The cache lock forces the replacement algorithm to point to an entry in the unlocked portion of data array 105. Consequently, this allocation uses the unlocked level pointed to by the replacement algorithm, and appropriate information in directory array 106 is modified. This process is referred to as a replacement because a new entry is being allocated over a valid entry.</p><p>If in step 506 the cache is not locked, then the process proceeds to step 507 whereby the replacement algorithm specifies any level for allocation. The process ends at step 509.</p><p>Advantages of the present invention are that allocation of entries in a locked portion of cache 101 is possible and the cache lock mechanism can be activated before, during, or after the entries intended to be locked are allocated.</p><p>A representative hardware environment for practicing the present invention is depicted in FIG. 6, which illustrates a typical hardware configuration of workstation 613 in accordance with the subject invention having central processing unit (CPU) 100 (see FIG. 1), and a number of other units interconnected via system bus 612. Workstation 613 shown in FIG. 6 includes random access memory (RAM) 614, read only memory (ROM) 616, and input/output (I/O) adapter 618 for connecting peripheral devices such as disk units 620 and tape drives 640 to bus 612, user interface adapter 622 for connecting keyboard 624, mouse 626, and/or other user interface devices such as a touch screen device (not shown) to bus 612, communications adapter 634 for connecting workstation 613 to a data processing network, and display adapter 636 for connecting bus 612 to display device 638. CPU 100 may include other circuitry not shown herein, which will include circuitry commonly found within a microprocessor, e.g., execution unit, bus interface unit, arithmetic logic unit, etc. CPU 100 may also reside on a single integrated circuit.</p><p>CPU 100 may retrieve requested in