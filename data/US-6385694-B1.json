write-back\u201d cache, where data values are not immediately passed on to the remainder of the memory hierarchy after a store operation. Caches can also be \u201cwrite-through,\u201d but this leads to increased demands on bus bandwidth. Write-back caches use state information bits to maintain consistency within the overall memory hierarchy (coherency), combined with the monitoring (snooping) of memory operations. One example of the state information is that supplied by the \u201cMESI\u201d cache coherency protocol, wherein a cache line can be in one of four coherency states: Modified, Exclusive, Shared or Invalid. Cache coherency protocols introduce further complexities and requirements into the interaction of the caches.</p><p>In light of the foregoing, it would be desirable to provide a method of speeding up core processing by improving the operation of the caches, particularly the L1 cache. It would be particularly advantageous if the method could provide values (instructions or operand data) more directly to processor components, i.e., without requiring the use of so many intervening queues and buffers, and allow more flexibility in the interaction between a cache and a processor or between vertically adjacent caches (e.g., L1 and L2) in a multi-cache hierarchy.</p><h4>SUMMARY OF THE INVENTION</h4><p>It is therefore one object of the present invention to provide an improved data processing system having one or more local caches in the memory hierarchy.</p><p>It is another object of the present invention to provide such an improved data processing system having a multi-level cache structure, and at least one layered cache wherein one or more cache functions are handled by a lower level cache.</p><p>It is yet another object of the present invention to provide a memory structure for a computer system which speeds up memory accesses by removing or distancing cache functions from the critical path of core execution.</p><p>The foregoing objects are achieved in a method of accessing values stored in a memory array of a computer system, comprising the steps of issuing a request from a device of the computer system to load a value from the memory array, the device having a first granularity for receiving memory lines from said memory array, and a second granularity for receiving a specific subset of the first granularity, and sending a pair of flags along with the request which specify which granularities are requested from the memory subsystem. If both granularities of data are to be returned to the requesting device, then the two granularities are returned via two separate data bus transactions. The invention may support heterogenous devices on the system bus. The requesting device could be an I/O device which may only be able to use the first granularity, in which case it sets the outbound flags to request only the first granularity. More particularly, the device may be a processing unit which includes at least one cache with cache lines having the first granularity, and a requested value having the second granularity is register data. When the cache issues a system bus address transaction due to a processor load request which missed in the cache, the cache may set the outbound flags to request only the second granularity, or the first granularity, or both granularities. The advantage of requesting only the second granularity (register data) is that it does not require that the cache controller allocate a full cache line reload buffer to receive the data. This approach enables the implementation of a larger number of queues in the cache controller not all of which require a data reload buffer large enough to hold a full cache line of data. Also, the advantage of requesting both the first granularity and the second granularity is that even if the full cache line of data is desired by the cache controller, the second granularity (the register data requested by the processor core) can typically be returned by the memory subsystem with a lower latency than that for a full cache line. Therefore, the register data can be forwarded to the requesting core before the full cache line which contains the requested data is received from memory. When the memory subsystem returns the requested data, the granularity of the data bus transaction is determined by a pair of inbound flags. The first flag identifies the data as being of the first granularity or the second granularity. If both granularities were requested, the second (smaller) granularity is always returned with the first of two separate bus transactions. When the second granularity is returned (in the first bus transaction), the second flag indicates whether the first granularity (the second bus transaction) will occur or not. This approach allows the memory subsystem to imprecisely return the first granularity even though both granularities were requested. Subsequently, this also means that even if the device requested both granularities, the device is still able to accept only the second (smaller) granularity. The advantage of returning only the second granularity (register data) is that it does not require that the memory controller allocate a full cache line data buffer to return the data. This enables the implementation of a larger number of queues in the memory controller not all of which require a data buffer large enough to hold a full cache line of data.</p><p>The above as well as additional objectives, features, and advantages of the present invention will become apparent in the following detailed written description.</p><h4>BRIEF DESCRIPTION OF THE DRAWINGS</h4><p>The novel features believed characteristic of the invention are set forth in the appended claims. The invention itself, however, as well as a preferred mode of use, further objectives, and advantages thereof, will best be understood by reference to the following detailed description of an illustrative embodiment when read in conjunction with the accompanying drawings, wherein:</p><p>FIG. 1 is a block diagram of a conventional superscalar computer processor, depicting execution units, buffers, registers, and the on-board (L1) data and instruction caches;</p><p>FIG. 2 is an illustration of one embodiment of a data processing system in which the present invention can be practiced;</p><p>FIG. 3 is a block diagram illustrating selected components that can be included in the data processing system of FIG. 2 according to the teachings of the present invention;</p><p>FIG. 4 is a block diagram of a processing unit constructed in accordance with one embodiment of the present invention, depicting operation of a cache structure which includes an L1 operand data cache;</p><p>FIG. 5 is a block diagram of a processing unit constructed in accordance with another embodiment of the present invention, depicting operation of a cache structure which includes an L1 instruction cache; and</p><p>FIG. 6 is a block diagram of a memory management unit constructed in accordance with another embodiment of the present invention, depicting operation of a translation lookaside buffer for storing page table entries.</p><?BRFSUM description=\"Brief Summary\" end=\"tail\"?><?DETDESC description=\"Detailed Description\" end=\"lead\"?><h4>DESCRIPTION OF AN ILLUSTRATIVE EMBODIMENT</h4><p>With reference now to the figures, and in particular with reference to FIG. 2, a data processing system <b>120</b> is shown in which the present invention can be practiced. The data processing system <b>120</b> includes processor <b>122</b>, keyboard <b>182</b>, and display <b>196</b>. Keyboard <b>182</b> is coupled to processor <b>122</b> by a cable <b>128</b>. Display <b>196</b> includes display screen <b>130</b>, which may be implemented using a cathode ray tube (CRT), a liquid crystal display (LCD), an electrode luminescent panel or the like. The data processing system <b>120</b> also includes pointing device <b>184</b>, which may be implemented using a track ball, a joy stick, touch sensitive tablet or screen, track path, or as illustrated a mouse. The pointing device <b>184</b> may be used to move a pointer or cursor on display screen <b>130</b>. Processor <b>122</b> may also be coupled to one or more peripheral devices such a modem <b>192</b>, CD-ROM <b>178</b>, network adapter <b>190</b>, and floppy disk drive <b>140</b>, each of which may be internal or external to the enclosure or processor <b>122</b>. An output device such as a printer <b>100</b> may also be coupled with processor <b>122</b>.</p><p>It should be noted and recognized by those persons of ordinary skill in the art that display <b>196</b>, keyboard <b>182</b>, and pointing device <b>184</b> may each be implemented using any one of several known off-the-shelf components.</p><p>Reference now being made to FIG. 3, a high level block diagram is shown illustrating selected components that can be included in the data processing system <b>120</b> of FIG. 2 according to the teachings of the present invention. The data processing system <b>120</b> is controlled primarily by computer readable instructions, which can be in the form of software, wherever, or by whatever means such software is stored or accessed. Such software may be executed within the Central Processing Unit (CPU) <b>150</b> to cause data processing system <b>120</b> to do work.</p><p>Memory devices coupled to system bus <b>105</b> include Random Access Memory (RAM) <b>156</b>, Read Only Memory (ROM) <b>158</b>, and nonvolatile memory <b>160</b>. Such memories include circuitry that allows information to be stored and retrieved. ROMs contain stored data that cannot be modified. Data stored in RAM can be changed by CPU <b>150</b> or other hardware devices. Nonvolatile memory is memory that does not lose data when power is removed from it. Nonvolatile memories include ROM, EPROM, flash memory, or battery-pack CMOS RAM. As shown in FIG. 3, such battery-pack CMOS RAM may be used to store configuration information.</p><p>An expansion card or board is a circuit board that includes chips and other electronic components connected that adds functions or resources to the computer. Typically, expansion cards add memory, disk-drive controllers <b>166</b>, video support, parallel and serial ports, and internal modems. For lap top, palm top, and other portable computers, expansion cards usually take the form of PC cards, which are credit card-sized devices designed to plug into a slot in the side or back of a computer. An example of such a slot is PCMCIA slot (Personal Computer Memory Card International Association) which defines type I, II and III card slots. Thus, empty slots <b>168</b> may be used to receive various types of expansion cards or PCMCIA cards.</p><p>Disk controller <b>166</b> and diskette controller <b>170</b> both include special purpose integrated circuits and associated circuitry that direct and control reading from and writing to hard disk drive <b>172</b>, and a floppy disk or diskette <b>74</b>, respectively. Such disk controllers handle tasks such as positioning read/write head, mediating between the drive and the CPU <b>150</b>, and controlling the transfer of information to and from memory. A single disk controller may be able to control more than one disk drive.</p><p>CD-ROM controller <b>176</b> may be included in data processing <b>120</b> for reading data from CD-ROM <b>178</b> (compact disk read only memory). Such CD-ROMs use laser optics rather than magnetic means for reading data.</p><p>Keyboard mouse controller <b>180</b> is provided in data processing system <b>120</b> for interfacing with keyboard <b>182</b> and pointing device <b>184</b>. Such pointing devices are typically used to control an on-screen element, such as a graphical pointer or cursor, which may take the form of an arrow having a hot spot that specifies the location of the pointer when the user presses a mouse button. Other pointing devices include a graphics tablet, stylus, light pin, joystick, puck, track ball, track pad, and the pointing device sold under the trademark \u201cTrack Point\u201d by International Business Machines Corp. (IBM).</p><p>Communication between processing system <b>120</b> and other data processing systems may be facilitated by serial controller <b>188</b> and network adapter <b>190</b>, both of which are coupled to system bus <b>105</b>. Serial controller <b>188</b> is used to transmit information between computers, or between a computer and peripheral devices, one bit at a time over a single line. Serial communications can be synchronous (controlled by some standard such as a clock) or asynchronous (managed by the exchange of control signals that govern the flow of information). Examples of serial communication standards include RS-232 interface and the RS-422 interface. As illustrated, such a serial interface may be used to communicate with modem <b>192</b>. A modem is a communication device that enables a computer to transmit information over standard telephone lines. Modems convert digital computer signals to interlock signals suitable for communications over telephone lines. Modem <b>192</b> can be utilized to connect data processing system <b>120</b> to an on-line information service or an Internet service provider. Such service providers may offer software that can be down loaded into data processing system <b>120</b> via modem <b>192</b>. Modem <b>192</b> may provide a connection to other sources of software, such as a server, an electronic bulletin board (BBS), or the Internet (including the World Wide Web).</p><p>Network adapter <b>190</b> may be used to connect data processing system <b>120</b> to a local area network <b>194</b>. Network <b>194</b> may provide computer users with means of communicating and transferring software and information electronically. Additionally, network <b>194</b> may provide distributed processing, which involves several computers in the sharing of workloads or cooperative efforts in performing a task. Network <b>194</b> can also provide a connection to other systems like those mentioned above (a BBS, the Internet, etc.).</p><p>Display <b>196</b>, which is controlled by display controller <b>198</b>, is used to display visual output generated by data processing system <b>120</b>. Such visual output may include text, graphics, animated graphics, and video. Display <b>196</b> may be implemented with CRT-based video display, an LCD-based flat panel display, or a gas plasma-based flat-panel display. Display controller <b>198</b> includes electronic components required to generate a video signal that is sent to display <b>196</b>.</p><p>Printer <b>100</b> may be coupled to data processing system <b>120</b> via parallel controller <b>102</b>. Printer <b>100</b> is used to put text or a computer-generated image (or combinations thereof) on paper or on another medium, such as a transparency sheet. Other types of printers may include an image setter, a plotter, or a film recorder.</p><p>Parallel controller <b>102</b> is used to send multiple data and control bits simultaneously over wires connected between system bus <b>105</b> and another parallel communication device, such as a printer <b>100</b>.</p><p>CPU <b>150</b> fetches, decodes, and executes instructions, and transfers information to and from other resources via the computers main data-transfer path, system bus <b>105</b>. Such a bus connects the components in a data processing system <b>120</b> and defines the medium for data exchange. System bus <b>105</b> connects together and allows for the exchange of data between memory units <b>156</b>, <b>158</b>, and <b>160</b>, CPU <b>150</b>, and other devices as shown in FIG. <b>3</b>. Those skilled in the art will appreciate that a data processing system constructed in accordance with the present invention may have multiple components selected from the foregoing, including even multiple processors.</p><p>Referring now to FIG. 4, one embodiment of the present invention allows data processing system <b>120</b> to more efficiently process information by speeding up the memory accesses performed by CPU <b>150</b>. In the illustrative embodiment, CPU <b>150</b> includes a multi-level cache hierarchy comprised of an upper, or L1 cache <b>200</b>, and a lower, or L2 cache <b>202</b>. Also depicted are a load/store unit <b>204</b>, and a plurality of register renames <b>206</b>. CPU <b>150</b> includes other (conventional) components not shown, such as fixed-point units, floating-point units, branch units, general purpose registers, special purpose registers, etc., some of which are interconnected with load/store unit <b>204</b> and register renames <b>206</b>. L1 cache <b>200</b> includes both operand data and instruction caches, although only the operand data components are shown. Those components include the L1 data directory <b>208</b> and the L1 data entry array <b>210</b>.</p><p>Noticeably absent in the L1 cache is any load queues (for requests from load/store unit <b>204</b>), and any reload buffers (for data provided to L1 data entry array from L2 cache <b>202</b> or system bus <b>105</b>). Any request for a load operation is sent along request bus <b>212</b> to L1 data directory <b>208</b> and L1 data entry array <b>210</b>. Directory <b>208</b> searches to see if the requested address matches one already present (an L1 hit). If the operation results in a cache hit, then the mechanism proceeds as in the prior art, with the read data being sourced by entry array <b>210</b> to one of the register renames <b>206</b> via a controller or multiplexer <b>220</b>.</p><p>If the load operation results in a miss, however, the load address that is coming out of request bus <b>212</b> is also being piped out to the lower level storage subsystem, specifically, to an L2 controller <b>214</b>, L2 directory <b>216</b>, and L2 entry array <b>218</b> (as explained further below, the requested address is delivered to the L2 components even if the load operation resulted in an L1 hit). This interc