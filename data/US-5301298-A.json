be used for non-instruction data storage.</p><p>Before describing the line buffer of FIG. 3, it is helpful to review what happens when the processing unit seeks to fetch an instruction and a miss occurs at the cache memory. For the described cache memory, each line of data is 32 bytes wide corresponding to 8 instructions. When the miss occurs, an entire line in the cache memory is filled, and then, the processing unit is able to retrieve the instruction (4 bytes) that it requested in that line. Consequently, once the miss occurs, it may be necessary that more bytes be transferred into the cache memory than are immediately needed before the processor is able to retrieve the instruction it requested.</p><p>The line buffer shown in FIG. 3 relieves this problem. The portion of the cache memory shown below the dotted line of FIG. 3 reflects the ordinary cache memory which includes instruction data cache 38 (similar to cache 23, except for instruction storage) and instruction tag storage section 37. The tag fields of the virtual address from the processing unit are coupled to the instruction tag storage section and compared in an ordinary manner with the stored tag fields. If a match occurs, one of the lines selected by the offset provides the instruction in an ordinary manner. Note, as is typically the case, the offset is provided to cache 38 allowing it to select the appropriate lines at the same time that the comparison process is being carried out in the tag storage section 37.</p><p>With the invented line buffer, in effect, an additional one line cache memory is added which is fully associative and additionally where fields of the data stored in the single line of data can be selected without the remainder of the line being present. The line buffer comprises a first storage means 42 for storing a virtual address (27 bits and at least one additional bit as described below) and a second storage means 44 for storing the data (32 bytes plus additional bits which will be described).</p><p>The storage means 42 and 44 in the currently preferred embodiment are fabricated using master-slave flip-flops which are well-known in the art. This arrangement permits reading and writing in a single memory cycle which, as will be seen, enables for instance, address and data to be read from the storage means 42 and 44 and new address and data to be read into the line buffer in a single cycle.</p><p>The storage means 42 stores both the tag field (20 bits) and the offset field (7 bits). This is in contrast to the storage section 37 where only the 20 bit tag field is stored. When the processing unit seeks an instruction from the cache memory, not only does the comparison occur of the tag fields within the storage 37, but also both the tag and offset fields from the processing unit are compared to the tag and offset fields stored within the storage means 42. Ordinary comparison means are included in storage means 42 for this purpose.</p><p>The storage means 42 includes an additional bit 43, a \"valid bit\". If a miss occurs, as will be described in greater detail, the contents of the storage means 42 (tag portion only) is transferred to storage section 37 and the offset is used to select lines within the cache 38. Then the data in storage means 44 is transferred into the cache 38. The tag and offset fields from the processing unit are then loaded into the storage means 42. The valid bit at this time is set to invalid. An ordinary memory cycle is used now to access the main memory. When the main memory returns a signal indicating that the data being accessed in the main memory is \"cacheable\" the valid bit 43 is set to its valid state. The signal indicating that the processing unit has requested cacheable data is identified as KEN/; this signal is currently used in the Intel 860, however, not with a line buffer. The use of this valid bit is described in conjunction with FIG. 12.</p><p>The storage means 44 is divided into four sections, each 64 bits wide. In addition, each of the sections includes an additional bit used to indicate if the data in its respective section is valid. For example, 8 bytes (2 instructions) are stored in the section 45. The bit 49 is used to indicate if the data in section 45 is valid. Similarly, there are bits associated with the sections 46, 47 and 48; there is one additional bit 51, used to indicate the validity of the entire line. This bit corresponds to the valid bits used in cache 38.</p><p>In the currently preferred embodiment, the data bus is 64 bits wide and hence, for each memory cycle a single section of the storage means 44 is filled. Assuming that data is loaded into the storage means 44 from left to right for a typical line fill, first the storage section 45 is filled on a first memory cycle and the valid bit 49 is set to its valid state. All the other valid bits associated with the storage means 44 remain in their invalid state. As more memory cycles occur, loading data into sections 44, 47 and 48, the associated valid bits for each of these sections change to their valid state. Once all the sections have valid data, the bit 51 is set to its valid state.</p><p>Data may be transferred, as will be discussed, from the first storage means 44 into the cache 38. When a transfer occurs the offset field from storage means 42 is used as an entry number into cache 38 and the data from storage means 44 is transferred into cache 38. Only the final valid bit 51 is stored within cache 38. As will be discussed, even if for example, only sections 45 and 46 have data, a transfer of the data to cache 38 can occur. Thereafter, on the next two memory cycles the data for the remaining half of the line is directly transferred into cache 38.</p><p>Importantly, the processing unit is able to read data from storage means 44 before the entire line fill occurs. After a first memory cycle where, for instance, section 45 receives two instructions from main memory, invalid bit 49 is set to its valid state. The processing unit through the use of the index field of the virtual address selects one or both of the instructions from section 45 and hence continues operating, even though the remaining sections 46, 47 and 48 have not been filled with instructions from main memory. This is in contrast to filling the entire line in cache 38 before such accessing is possible with the prior art. In effect, one may look at this as a \"fifth way\" set associativity.</p><p>Referring now to FIG. 12, assume that the processing unit seeks to read an instruction as shown by block 55. The address (both tag and offset fields) for this instruction are coupled to the storage means 42 of FIG. 3 and compared with the contents of the storage means 42. Simultaneously, the tag field for the instruction, in an ordinary manner, is compared with the tag fields stored within section 37 while the offset field selects lines in cache 38. A hit can occur either within the section 37 or the storage means 42. If a hit occurs within section 37, the instruction is provided in an ordinary manner from the cache 38. If the hit occurs because of the contents of the storage means 42 (both the tag and offset fields must match) then the appropriate data is selected from storage means 44, of course, assuming it is valid.</p><p>Assume that the fetch illustrated by block 55 results in a miss both in the storage means 42 and section 37. This miss causes an external memory cycle to be initiated, that is, the processor seeks to obtain the instruction from main memory. While this is occurring the valid contents, if any, of storage means 42 are moved from the storage means. (In fact, the contents of the line buffer are written to cache while doing the next linefill of the line buffer). The tag field is transferred to section 37 and replaces a tag field stored within section 37 under a predetermined replacement algorithm (e.g., random replacement). The offset field from the storage means 42 provides the entry number to allow the data from the storage means 44 to be transferred to cache 38. The tag and offset fields of the address that caused the miss are then transferred into the storage means 42. This is shown by block 56.</p><p>Assume now that the address loaded into storage means 42 is cacheable; once the KEN  signal has been returned, the bit 43 is set to its valid state. If the data sought is not cacheable, on the next miss the new address is loaded into the storage means 42 and its previous contents discarded.</p><p>Once the data is returned from main memory, and is loaded into at least one of the sections of the storage means 44 it is available to the processing unit, as previously discussed. Typically in processor operation because of the pipelining, the next instruction will be fetched before the previous instruction has been returned from main memory. This is shown by block 58 is FIG. 12. Two possible conditions are shown once this next instruction fetch occurs. One is a hit at the line buffer and the second is a miss at the line buffer. Another possibility is that a hit occurs within section 37, and in this event the instruction is selected from storage 38 after the previous instruction is returned from main memory.</p><p>Assume now that a miss occurs at the line buffer. As shown by block 59, the data contents, if any, are moved to the cache 38 with the offset field from the storage means 42 providing an entry number as previously discussed and with a tag field from storage means 42 being entered into section 37. This clears the way for the new instruction address to be placed into storage means 42. An external memory cycle is initiated and the new data, once returned from main memory, is placed within the storage means 44.</p><p>If a hit occurs in the line buffer for the next instruction fetch, such hit could occur either before or after the previous instruction has been returned. If it occurs before the previous instruction has been returned as indicated by block 60, the following indicators are present: the address valid bit 43 is in its valid state and the valid bit associated with the previously requested instruction is in its invalid state. Under these conditions, the processing unit knows that the previous instruction is on its way from main memory and that is should wait for the instruction as indicated by block 60. If, on the other hand, the hit occurs after the previous instruction has been returned, the valid bit associated with the instruction, for example bit 49, is in its valid state and the processing unit can read the instruction from the storage means 44 once the previous instruction has been, of course, taken by the processor.</p><p>Thus, the line buffer of FIG. 3 permits the processing unit to proceed before an entire line fill occurs and thereby saves the time normally associated with filling an entire line in a cache memory.</p><h4>Implementation of Cache Coherency Protocols</h4><p>In the following description, the known protocols write-through, write-back and write-once are discussed. In this connection the letters \"M\", \"E\", \"S\" and \"I\" are used; sometimes these letters are referred to collectively as MESI. For the write-once protocol \"I\" indicates that the data is invalid, \"S\" indicates that the data is shared, for example, that the data in addition to being in main memory, is in another cache memory. \"E\" indicates that the data is exclusive, that is, it is in only one cache memory and main memory and not in other cache memories. \"M\" indicates that the data is modified, and that the data in main memory is incorrect. As currently implemented, each line of data (non-instruction data) includes bits to indicate one of the four protocol states \"M\", \"E\", \"S\", \"I\". For the write-through protocol only the \"I\" and \"S\" states are used; for the write-back protocol the \"I\", \"E\" and \"M\" states are used.</p><p>Importantly, as will be seen, the processor can implement any one of the three protocols. FIG. 8 shows two processors interconnected, as can be done with the present invention, to provide a write-once protocol. In this regard, there are several terminals or pins associated with the processors which are not found on the Intel 860.</p><p>Referring first to FIG. 4, the processor terminals and the signals on these terminals, insofar as they are needed to understand the various protocols are shown. Line 62 is intended to be the demarcation between the processor (chip) and its external environment. Hence, above the line 62 is internal to the processor and below the line external to the processor.</p><p>Beginning at the far left, the bidirectional data bus is shown. Also, there is a bidirectional address bus; this bus, as mentioned, is able to sense addresses on the external address bus and for this reason is bidirectional. There are two address strobes, EADS  and ADS . When the EADS  signal is low, the external addresses are valid. Similarly, when the ADS  signal is low, the internal addresses are valid.</p><p>A protocol selecting terminal is provided which permits selecting of the protocols. This terminal is identified as WB/WT  (write-back/not write-through). The connections made to this terminal are described later.</p><p>The commonly used signal which indicates whether a memory cycle is a write or read cycle (W/R ) is also shown in FIG. 4 since it is subsequently discussed.</p><p>The processor receives a signal which indicates to the processor that it should invalidate data. This signal is shown as \"INV\". When the processor is sensing external addresses (snooping) if this signal is high the processor places the corresponding data (if found in its cache memory) in the invalid \"I\" state.</p><p>The \"BOFF \" signal, when applied to the processor, causes the processor to back off from completing a memory cycle. The use of this signal is described later.</p><p>The processor receives the EWBE  signal, \"external write buffer not empty\". This signal is low when the external right buffer is empty.</p><p>The HIT  signal is provided by the processor when a hit occurs for an externally sensed address. This signal is nominally high and drops in potential when a hit occurs and the corresponding data is in the \"E\", \"S\", or \"M\" states. The HITM  signal drops in potential when a hit occurs for an externally sensed address and the corresponding data is in the \"M\" state. Thus, if the processor is snooping and the corresponding data is in the \"M\" state, both the HIT  and HITM  signals drop in potential.</p><p>Finally, the HOLD  signal causes the processor to, in effect, halt operations. This is used in connection with a bus arbitrator and shall be described in conjunction with FIG. 8.</p><p>In the following discussion, the states of the bits representing \"M\", \"E\", \"S\" and \"I\", for the different protocols are discussed along with the conditions under which they change. This is illustrated in terms of state diagrams rather than, for example, gates. This is done to provide a clearer understanding of the present invention. It will be obvious to one skilled in the art that ordinary logic may be used to implement the state diagrams.</p><p>FIGS. 5, 6 and 7 show the connection made to the WB/WT  terminal to obtain the different protocols. These figures apply to a case where a single processor is used in a system.</p><p>Referring first to FIG. 5, assume that the processor 63, which contains the invented cache memory and its associated logic, has its WB/WT  terminal connected to ground. This implies that write-through is true and hence, that the write-through protocol is implemented. For the write-through protocol, the data is either in the invalid (I) state or the shared (S) state which, for a single processor environment indicates that the data in the cache memory is valid. With the ground potential coupled to line 66, the cache memory only associates the \"I\" or \"S\" state with each line of data. If the processor initiates a read cycle, the data read into the cache memory is valid as indicated by the change of state from \"I\" to \"S\" (arrow 71) shown in FIG. 5. If the processor reads the data from the cache memory, the data remains in the \"S\" state as indicated by arrow 73. The data can be invalidated as indicated by arrow 72 by, for example, the purging of data from the cache memory.</p><p>Referring to FIG. 6, the processor 64 is shown which may be identical to processor 63 except that its WB/WT  terminal is connected to V<sub>cc</sub> (e.g., 5 volts) by line 65. This implies that the write-back protocol is in use and that therefore, for each line of data, the bits indicating \"I\", \"E\" or \"M\" apply. When a line fill occurs, the state changes from invalid to \"E\" indicating that the processor has as good a copy as is found in the main memory. If a write hit occurs, the state changes from \"E\" to \"M\". The states and their transitions for the write-back protocol are as currently used in the Intel 860.</p><p>Referring to FIG. 7, the processor 65 which again may be identical to the processors 63 or 64 is shown. This time the WB/WT  terminal is connected to line 67 by line 66, line 66 being the W/R  terminal. This connection provides the write-once protocol. For example, after every line fill, the line will be in the \"S\" state because W/R  is low for read cycles. This is shown in FIG. 7 by arrow 74 and corresponds to the arrow 71 of FIG. 5 where line 66 is connected to a low potential (ground). The subsequent write to this line will be write-through's to main memory because of the \"S\" state. When doing the first write, the processors samples the WB/WT terminal and determines that it is high because of the write cycle and changes state to the \"E\" state as shown by arrow 75 (write-once). All subsequent writes to this line will not show up on the bus because of the change to the \"M\" state as shown by arrow 76. Consequently, the write-once protocol is realized.</p><p>Referring now to FIG. 8, two processors 76 (P1) and 77 (P2) are shown coupled to a shared data bus 81 and a shared address bus 82. The processors 76 and 77 may be identical to the previously discussed processors, that is they include the cache memory of the present invention and its associated logic.</p><p>The shared bus 81 and 82 are coupled to main memory 79 and an external write buffer 78 which shall be subsequently described.</p><p>In FIG. 8 the various interconnections for the processor 76 and 77 are illustrated that implement write-once protocol for shared data (HIT asserted for snooping processor while the other processor is doing a linefill). As will be seen, these interconnections permit the coherent caching with a minimum of glue logic.</p><p>As shown by lines 84 and 86, the output address strobe terminal (ADS  from one processor is coupled to the external address strobe terminal of the other processor. This assures that each of the processors snoops on each others cycles. That is, when processor P1 puts out an address on bus 81, the ADS  strobe signal on line 86 causes processor 77 to read the address. Note that this strobe signal may be coupled to other components in the system such as the buffer 78 and memory 79.</p><p>The HIT  terminal of one processor is coupled to the WB/WT  terminal of the other processor by lines 82 and 85. This assures that when one processor is reading data to fill a line in its cache memory, and the other processor has the same data, the processors will indicate that the data is in the \"S\" state. This does not occur if the HITM  signal is low as will be described later in conjunction with the BOFF  signal.</p><p>Assume that processor 76 is reading a line of data from main memory for its cache memory and that line is also present in processor 77. Assume further that the line is processor 77 in the \"E\" state. The hit signal on line 82 drops in potential causing the data read into processor 76 to be in the \"S\" state as shown by line 93 of FIG. 9. In the case of processor 77 which is snooping, the \"E\" state changes to the \"S\" state as indicated by line 100 of FIG. 10b. For the processor 77 the HIT  signal is low indicating that the data is present in the processor 77. However, the HITM  signal is high since the data is not in the \"M\" state. Also, since this is a read cycle by processor 76 the invalid signal on line 87 remains low. Consequently, both processors will indicate the data is in the \"S\" state, that is the data is shared by the cache memories.</p><p>The W/R  signal of one processor is connected to the INV terminal of the other processor. This ensures invalidation of the data in one processor while the other processor is writing. Lines 83 and 87 of FIG. 8 accomplish this.</p><p>Assume that processor 76 is writing and that data for that address is found in processor 77. The signal on line 87 will be high, causing the corresponding data in processor 77 to assume the \"I\" state. This is shown in FIG. 10a by arrow 97, in FIG. 10b by arrow 98 and in FIG. 10c by arrow 99. Also as shown in FIG. 10a, when the data in the processor 77 is in the \"S\" state for the described conditions, the HIT  signal will be low and the HITM  signal will be high since the data in the cache memory is in the \"S\" state, not \"M\"  state. In FIG. 10b, when the data is in the \"E\" state, it also changes to the \"I\" state as indicated by arrow 98, once again the HIT  signal is high. A transition occurs from the \"M\" to \"S\" state if the INV pin is active with EADS .</p><p>In FIG. 10c if the data in processor 77 happens to be in the \"M\" state, as indicated by arrow 99, it is invalidated. Note that the HIT  and HITM signal are both in their low states.</p><p>When a processor is snooping and senses that another processor is reading data, if the processor is already in the \"S\" state, it remains in the \"S\" state as shown by arrow 76 of FIG. 10a. Here the snooping processor indicates that a hit occurred and that the data is not in its modified state.</p><p>As shown in FIG. 8, the HITM  terminal of one processor is coupled to the back-off terminal of the other processor and also to the bus arbitrator by lines 91 and 92. This assures that when one processor contains modified data, the other processor is prevented from reading invalid data from the main memory. For example, if processor 76 contains modified data, the data at the corresponding address in the main memory 79 is incorrect. If processor 77 should attempt to read that data, the HITM  signal on line 91 will go low causing the processor 77 to back off. This will be explained later.</p><p>The remainder of FIG. 9 shows the standard updating for the write-once protocol for a processor, such as either processor 76 or 77 as it reads and writes. As indicated by the arrow 94, once in the \"S\" state, a processor may read from its cache memory without changing the \"S\" state. As indicated by arrow 95, once a processor writes to its cache (first write) the state changes to \"E\" and the data is read into the main memory. When another write occurs to that location, it changes state to the \"M\" state as indicated by arrow 101 indicating that the only true copy of the data is contained in the cache memory. This \"M\" state and in particular, the HITM  signal prevents the other processor from reading the 