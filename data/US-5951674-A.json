This is drastically different from the approach used in conventional scalar and superscalar processors, which at run time perform the analysis and decisions regarding which operations are executed in each cycle (known as dynamic scheduling), so that the detailed features of the processor need not be known by the compiler. In other words, the separation among architecture and implementation that is common practice in processor design for scalar and superscalar implementations has been sacrificed in VLIW implementations, in order to better exploit the capabilities of the hardware by the compiler/programmer.</p><p>Although the benefits of exposing the details of the implementation to the compiler/programmer are clear, this has lead to the perception that such an exposure is a requirement for a VLIW processor. Thus, there is a need to develop a mechanism that represents a VLIW program without depending on the specific aspects of an implementation, so that the perceived requirement is sustained.</p><h4>SUMMARY OF THE INVENTION</h4><p>It is therefore an object of the present invention to eliminate the exposure of a VLIW processor implementation at the architecture level and thereby achieve object-code compatibility in a processor architecture encompassing scalar, superscalar and VLIW implementations.</p><p>It is another object of the invention to provide object-code compatibility across VLIW processors having varying levels of parallelism.</p><p>It is a further object of the invention to provide object-code compatibility among VLIW processors with different organizations, which object code can be executed by sequential processors.</p><p>According to the present invention, a new approach to achieve object-code compatibility in a processor architecture is taken, allowing the same program to be executed in scalar, superscalar and VLIW implementations of the same architecture. In this invention, there is provided a mechanism which allows a VLIW program to be represented in an implementation-independent manner, and which conveys in straight-forward form the fine-grain parallelism extracted by the compiler/programmer. The invention relies on functions that incorporate implementation-dependent features into a VLIW program while the program is being executed, functions which are preferably integrated into the instruction cache (I-cache) reload/access logic but could also be integrated at other levels of the memory hierarchy. There is a one-to-one correspondence among primitive operations in the original and the translated VLIW programs. In this way, programs are represented in an implementation-independent manner (i.e., without reflecting the organization of the processor where they are executed), the implementation-specific aspects are introduced as part of the instruction cache reload/fetch logic, and the simplicity in instruction dispatch logic that is characteristic of VLIW processors is preserved. This allows for object-code compatibility among VLIW processors with different parallel processing capabilities. Moreover, the VLIW programs represented in this manner can also be executed by sequential processors, so that the invention allows object-code compatibility with scalar and superscalar implementations.</p><p>The mechanism which incorporates the implementation-dependent features into a VLIW program transforms the original program into one which can be executed in a given processor implementation, by decomposing those VLIWs requiring more resources than the resources available in the processor into two or more smaller VLIWS which fit the implementation constraints, without changing the semantics of the original program. Smaller VLIWs are executed directly. The mechanism does not attempt to combine small VLIWS into larger ones, neither to move primitive operations from one VLIW to another.</p><p>The mechanism provided in this invention can also be used to handle programs in which there may exist dependencies among the operations within a VLIW; however, such a feature is not described here.</p><?BRFSUM description=\"Brief Summary\" end=\"tail\"?><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"lead\"?><h4>BRIEF DESCRIPTION OF THE DRAWINGS</h4><p>The foregoing and other objects, aspects and advantages of the invention will be better understood from the following detailed description of a preferred embodiment of the invention with reference to the drawings, in which:</p><p>FIG. 1 is a diagram of a tree-instruction illustrating the basic characteristics of a VLIW program;</p><p>FIG. 2 is a diagram of the tree-instruction of FIG. 1 illustrating a pruning operation;</p><p>FIG. 3 is a flow diagram showing the logic of the translation process according to the invention;</p><p>FIG. 4 is a memory map showing variable-length VLIWs in the instruction cache;</p><p>FIG. 5 is a block diagram of a VLIW processing system according to the present invention;</p><p>FIG. 6 is a block diagram of a VLIW processing system embodying the present invention;</p><p>FIG. 7 is a pictorial representation of the format of a tree-instruction stored in the main memory of FIG. 6 prior to pruning, and the format of a pruned tree-instruction stored in the L2-cache memory of FIG. 6 after pruning;</p><p>FIG. 8 is a pictorial representation of the pruned tree-instructions of FIG. 2 stored in the L2-cache memory of FIG. 6;</p><p>FIG. 9 is a pictorial representation of the format of a pre-decoded representation of the pruned tree-instruction stored in the instruction cache memory of FIG. 6;</p><p>FIG. 10 is a block diagram of the instruction cache reload unit of FIG. 6;</p><p>FIG. 11 is a pictorial representation of the format of the pre-decoded representation of the pruned tree-instruction of FIG. 8 as stored in the instruction cache memory of FIG. 6;</p><p>FIG. 12 is a pictorial representation of the format of the pre-decoded representation of the pruned tree-instruction stored in the instruction cache memory of FIG. 6, and the format of a VLIW derived from such pre-decoded representation as stored in the instruction register of FIG. 6;</p><p>FIG. 13 is a pictorial representation of an example of the VLIWS derived from the pre-decoded representation of FIG. 12 as stored in the instruction register of FIG. 6;</p><p>FIG. 14 is a block diagram illustrating the instruction cache memory, I-cache fetch unit and instruction register of FIG. 6;</p><p>FIG. 15 is a block diagram of the processor unit of FIG. 6;</p><p>FIG. 16 is a pictorial representation of an instruction cycle of the processor unit of FIG. 15;</p><p>FIG. 17 is a block diagram of the branch unit of the processor unit of FIG. 15; and</p><p>FIG. 18 is pictorial representation illustrating the operation of the TEM Generator unit of FIG. 17 in processing the first VLIW of FIG. 13.</p><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"tail\"?><?DETDESC description=\"Detailed Description\" end=\"lead\"?><h4>DETAILED DESCRIPTION OF THE PRESENT INVENTION</h4><p>The description of the present invention that follows is broken down into two parts:</p><p>A. Overview of the Present Invention</p><p>B. Example of Computer Processing Unit that Embodies the Present Invention</p><p>A. Overview of the Present Invention</p><p>The invention relies on the following aspects, described in more detail later:</p><p>A chunk is the minimal unit of program specification. A chunk may correspond to a single memory word (a memory word is 32 bits), or to several memory words (for example, 4 words), depending on the specific architecture. As a minimum, a processor is capable of executing simultaneously all the operations in one chunk; a processor may also execute simultaneously several chunks, depending on the implementation.</p><p>A tree-instruction (TI) is a set of chunks, so that the size of a tree-instruction is a multiple of the size of a chunk. Each tree-instruction consists of an unlimited multiway branch and an unlimited number of primitive operations, so that tree-instructions have variable length. There may exist limitations on the number and type of operations per chunk, depending on the specific architecture.</p><p>A VLIW program is a set of tree-instructions.</p><p>Throughout the execution of the VLIW program, and as needed by it, the variable-length tree-instructions are converted into variable-length VLIWs which consist of one or several chunks, but whose overall computing requirements do not exceed the computing capabilities of the processor. A tree-instruction which exceeds the computing capabilities of the processor is decomposed into two or more variable-length VLIWs which may be executed sequentially; this decomposition is always performed at a chunk boundary.</p><p>The decomposition may be performed at any level of the memory hierarchy but it is performed preferably at I-cache replacement time. In such a case, the tree-instructions are stored in main memory of the computer system; the I-cache reload logic reads the tree-instructions from main memory, formats them as variable-length VLIWs (up to the maximum size possible), and stores them in the I-cache.</p><p>The processor executes fixed-length VLIWs extracted from the I-cache; the size and computing requirements of these fixed-length VLIWs match the computing capabilities of the processor. Shorter VLIWS that may exist in the I-cache are expanded to match the fixed-size VLIWS; the expansion may consist of aligning the operations in a shorter VLIW to suitable positions within the fixed-length VLIW, introducing no-op operations to fill empty slots. Alternatively, shorter VLIWS extracted from the I-cache may be augmented with the adjacent primitive operations (beyond their end); these extra primitive operations are disabled from execution by the generation of execution masks during the I-cache access process, masks that exclude the operations which do not belong to the short VLIWS.</p><p>As a result, the processor features that are specific to an implementation are incorporated during the execution of the VLIW program, for example by the I-cache reloading and I-cache accessing processes as described above. These processor features include aspects such as maximum number of branches and other primitive operations per VLIW, position of operations within a VLIW, among others. In other words, implementation-independent tree-instructions are translated into implementation-dependent VLIWs, transparently to the compiler/programmer.</p><p>Referring now to the drawings, and more particularly to FIG. 1, there is shown a graphical representation of a tree-instruction. In the practice of the invention, a VLIW program consists of a set of tree instructions having the following characteristics in terms of their graphical representation:</p><p>Tree-instructions are composed of internal nodes, arcs, and leaves.</p><p>Internal nodes correspond to conditional branch instructions; that is, binary tests on condition codes (the condition codes are set by operations on tree-instructions executed previously). Each internal node generates two arcs. The right outgoing arc is selected if the outcome of the test is true; otherwise, the left outgoing arc is selected. A set of internal nodes represents a multiway tree. Only one path within the tree (the selected path) is executed to completion, which is determined by the outcome of the tests on the condition codes; the other paths are discarded. A tree-instruction may have no internal nodes, in which case the tree instruction has a single path.</p><p>Each leaf corresponds to an unconditional branch (a destination target); that is, the identification of the next tree-instruction to be executed when the leaf is in the selected path.</p><p>Primitive operations other than branches are associated with the arcs. Only those primitive operations associated with the arcs on the selected path of the tree are executed to completion.</p><p>All the operations on each path of a tree-instruction are subject to sequential semantics; that is, all operations are subject to a precedence order determined by their appearance on the tree. Operations that appear later in a path cannot use or target a resource which is the target of a previous operation in the path. (If that is not the case, the operations are dependent and cannot be executed in parallel.)</p><p>The sequential semantics feature is the key factor for achieving object-code compatibility among scalar and VLIW implementations. All the operations placed in a tree-instruction by a VLIW compiler are independent (i.e., executable in parallel) and match the requirements per chunk of the particular architecture; how